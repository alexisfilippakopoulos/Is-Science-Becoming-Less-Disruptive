{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import Bunch\n",
    "import regex as re\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AdamW\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We establish a connection to our database using the sqlite module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sqlite3.connect('publications_graph.db')\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the schema for all tables in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Name: works\n",
      "Table Schema: CREATE TABLE works(\n",
      "published_year,\n",
      "published_month,\n",
      "abstract,\n",
      "title,\n",
      "doi,\n",
      "published_day\n",
      ")\n",
      "Table Name: work_references\n",
      "Table Schema: CREATE TABLE work_references(\n",
      "work_id,\n",
      "doi\n",
      ")\n",
      "Table Name: author_affiliations\n",
      "Table Schema: CREATE TABLE author_affiliations(\n",
      "author_id,\n",
      "name\n",
      ")\n",
      "Table Name: work_subjects\n",
      "Table Schema: CREATE TABLE work_subjects(\n",
      "name,\n",
      "work_id\n",
      ")\n",
      "Table Name: work_authors\n",
      "Table Schema: CREATE TABLE work_authors(\n",
      "work_id,\n",
      "id,\n",
      "orcid\n",
      ")\n",
      "Table Name: cdindex\n",
      "Table Schema: CREATE TABLE cdindex(doi, cdindex)\n",
      "Table Name: data\n",
      "Table Schema: CREATE TABLE data(\n",
      "  doi,\n",
      "  title,\n",
      "  abstract,\n",
      "  cdindex,\n",
      "  published_month,\n",
      "  published_year\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT name, sql FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "for table in tables:\n",
    "    print(\"Table Name:\", table[0])\n",
    "    print(\"Table Schema:\", table[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new table by joining the abstracts with the cdindex based on doi column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table data already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_128784\\2658864826.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CREATE TABLE data AS SELECT works.doi, title, abstract, cdindex, published_month, published_year FROM cdindex JOIN works ON cdindex.doi = works.doi WHERE cdindex IS NOT NULL'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: table data already exists"
     ]
    }
   ],
   "source": [
    "cursor.execute('CREATE TABLE data AS SELECT works.doi, title, abstract, cdindex, published_month, published_year FROM cdindex JOIN works ON cdindex.doi = works.doi WHERE cdindex IS NOT NULL')\n",
    "connection.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put our data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>cdindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;jats:p&gt;The photolysis of dilute solutions of octacyclosulphur or hexacyclosulphur in n-hexane with 253.6 nm UV radiation produces S and possibly S&lt;jats:sub&gt;2&lt;/jats:sub&gt;. The ‘ring-opening’ yields of these sulphur molecules range from 0.2 to 0.7. When the hydrogen end-capped polyyne C&lt;jats:sub&gt;10&lt;/jats:sub&gt;H&lt;jats:sub&gt;2&lt;/jats:sub&gt; is irradiated in n-hexane, it transforms into unidentified products with a quantum yield of 3×10&lt;jats:sup&gt;−5&lt;/jats:sup&gt;. When octacyclosulphur is added to the solution, the yield rises to 7×10&lt;jats:sup&gt;−3&lt;/jats:sup&gt;. The putative sulphur-bearing product(s) could not be identified. It is suggested that sulphur-bearing molecules might be formed in astronomical settings by reactions of carbon molecules having triple or double C—C bonds with photolytically produced S and/or S&lt;jats:sub&gt;2&lt;/jats:sub&gt;.&lt;/jats:p&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;jats:p&gt;Examples are given of unforeseen damage or difficulties arising during or after construction of buildings, wharves, foundations, tunnels, in-ground storage, pipe lines, and embankments. The underlying potentially latent mechanisms of groundwater are classified into four groups, namely water pressure changes, physical changes, erosion, and affects of earthworks, in order to assist early identification of some of the types of change in ground properties which may be induced by site operations and may lead to damage. It is concluded that otherwise unforeseen damage is more likely to be averted by a greater degree of investigation during construction into the consequences of the construction sequences, method and plant used.&lt;/jats:p&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;jats:p&gt; Acute hypoxia causes pulmonary vasoconstriction and coronary vasodilation. The divergent effects of hypoxia on pulmonary and coronary vascular smooth muscle cells suggest that the mechanisms involved in oxygen sensing and downstream effectors are different in these two types of cells. Since production of reactive oxygen species (ROS) is regulated by oxygen tension, ROS have been hypothesized to be a signaling mechanism in hypoxia-induced pulmonary vasoconstriction and vascular remodeling. Furthermore, an increased ROS production is also implicated in arteriosclerosis. In this study, we determined and compared the effects of hypoxia on ROS levels in human pulmonary arterial smooth muscle cells (PASMC) and coronary arterial smooth muscle cells (CASMC). Our results indicated that acute exposure to hypoxia (Po&lt;jats:sub&gt;2&lt;/jats:sub&gt; = 25–30 mmHg for 5–10 min) significantly and rapidly decreased ROS levels in both PASMC and CASMC. However, chronic exposure to hypoxia (Po&lt;jats:sub&gt;2&lt;/jats:sub&gt; = 30 mmHg for 48 h) markedly increased ROS levels in PASMC, but decreased ROS production in CASMC. Furthermore, chronic treatment with endothelin-1, a potent vasoconstrictor and mitogen, caused a significant increase in ROS production in both PASMC and CASMC. The inhibitory effect of acute hypoxia on ROS production in PASMC was also accelerated in cells chronically treated with endothelin-1. While the decreased ROS in PASMC and CASMC after acute exposure to hypoxia may reflect the lower level of oxygen substrate available for ROS production, the increased ROS production in PASMC during chronic hypoxia may reflect a pathophysiological response unique to the pulmonary vasculature that contributes to the development of pulmonary vascular remodeling in patients with hypoxia-associated pulmonary hypertension. &lt;/jats:p&gt;</td>\n",
       "      <td>-0.002938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;jats:title&gt;Abstract&lt;/jats:title&gt;\\n               &lt;jats:p&gt;Despite rapid advances in the stem cell field, the ability to identify and track transplanted or migrating stem cells in vivo is limited. To overcome this limitation, we used magnetic resonance imaging (MRI) to detect and follow transplanted stem cells over a period of 28 days in mice using an established myocardial infarction model. Pluripotent mouse embryonic stem (mES) cells were expanded and induced to differentiate into beating cardiomyocytes in vitro. The cardiac-differentiated mES cells were then loaded with superparamagnetic fluorescent microspheres (1.63 μm in diameter) and transplanted into ischemic myocardium immediately following ligation and subsequent reperfusion of the left anterior descending coronary artery. To identify the transplanted stem cells in vivo, MRI was performed using a Varian Inova 4.7 Tesla scanner. Our results show that (a) the cardiac-differentiated mES were effectively loaded with superparamagnetic microspheres in vitro, (b) the microsphere-loaded mES cells continued to beat in culture prior to transplantation, (c) the transplanted mES cells were readily detected in the heart in vivo using noninvasive MRI techniques, (d) the transplanted stem cells were detected in ischemic myocardium for the entire 28-day duration of the study as confirmed by MRI and post-mortem histological analyses, and (e) concurrent functional MRI indicated typical loss of cardiac function, although significant amelioration of remodeling was noted after 28 days in hearts that received transplanted stem cells. These results demonstrate that it is feasible to simultaneously track transplanted stem cells and monitor cardiac function in vivo over an extended period using noninvasive MRI techniques.&lt;/jats:p&gt;\\n               &lt;jats:p&gt;Disclosure of potential conflicts of interest is found at the end of this article.&lt;/jats:p&gt;</td>\n",
       "      <td>-0.004497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;jats:title&gt;Abstract&lt;/jats:title&gt;\\n               &lt;jats:p&gt;For the regenerative therapy of osteochondral defects – deep lesions of the articular cartilage in which the underlying bone tissue is already affected too – special implant materials and scaffolds are needed. In this study, two new approaches will be presented, leading to biphasic, but monolithic scaffold materials. Both consist of a mineralised layer for filling of the bony part of the defect and a non-mineralised one for the chondral part. Due to the preparation methods, both layers are fused together to give a unified whole without need of any artificial joining. The resulting materials, either based on collagen, hyaluronic acid and hydroxyapatite or calcium alginate gels and hydroxyapatite, seem to be suitable scaffolds for cultivating chondrocytes and osteoblasts – and therefore can act as matrices for tissue engineering of osteochondral grafts.&lt;/jats:p&gt;</td>\n",
       "      <td>-0.004373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80276</th>\n",
       "      <td>&lt;jats:p&gt;The nymphal instars I and III - V of Sigara (Tropocorixa) denseconscripta (Breddin, 1897) are figured and described in detail, for the first time, with emphasis on morphometry and chaetotaxy of selected structures. The useful characters to identify the nymphal instars and the nymphs of the species of Sigara are provided.&lt;/jats:p&gt;</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80277</th>\n",
       "      <td>&lt;jats:p&gt; The possible effects of a wide range of sociodemographic and environmental factors on the incidence and distribution of petechiae were investigated in 485 sudden infant death syndrome (SIDS) cases from the New Zealand Cot Death Study. The number (nil, few, many) of macroscopic petechial hemorrhages in the visceral pleura, capsule of thymus, and epicardium was recorded in 458 of 474 autopsied SIDS cases. Other information was obtained from parental interview and obstetric records. Univariate analysis showed highly significant relationships ( P ≤ 0.005) between the frequency of petechiae at one or more sites and socioeconomic status, parity, breast feeding, age at death, time of death, sleep position, and head covering at death and lesser but significant relationships ( P ≤ 0.05) with Maori ethnicity, birth weight, gestation, pacifier use, and bed sharing. After multivariate analysis, significant associations remained between increased frequencies of thymic petechiae and parity (P = 0.0001), age at death (P = 0.0003), Maori ethnicity (P = 0.0019), pacifier use (P = 0.0001), and head covering at death (P = 0.0032); between increased frequencies of epicardial petechiae and head covering at death (P = 0.008) and an estimated time of death between 00:00 and 05:59 h ( P = 0.056); and between increased frequencies of pleural petechiae and maternal smoking ( P = 0.058) and parity ( P = 0.022). There was a decreased frequency of pleural petechiae in infants placed prone for their final sleep ( P = 0.058). The distribution and frequency of petechiae are affected by environmental factors, including known risk factors for SIDS, but these factors occur inconsistently across the three sites. The findings imply differences in the pathogenesis at each site but do not provide consistent support for previous theories of causation of petechiae. &lt;/jats:p&gt;</td>\n",
       "      <td>-0.007576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80278</th>\n",
       "      <td>&lt;jats:p&gt;After electroconvulsive therapy (ECT), many patients experience a decrement in their mnestic capacity. We studied episodic memory in eight severely depressed patients treated with a course of right-unilateral ECT. For this purpose, a testing instrument was constructed by the authors. It was made of paper cards that held four pieces of information, namely a word, a number, a figure, and the color of the card. One of the cards was presented to the patients and the respective information was asked for on the subsequent day. Patients were tested every morning during the first two weeks of the ECT course. About half of the responses were correct. Patients did best in recalling the color; they did worst in recalling the number. Seven of the patients showed verbal perseverations. This is in accordance with the literature on perseveration in patients with neurologic deficits, especially in proactive-inhibitory tasks. Perseveration may be attributed to a deficit in selective attention, producing an arousal of irrelevant cues.&lt;/jats:p&gt;</td>\n",
       "      <td>-0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80279</th>\n",
       "      <td>&lt;jats:p&gt;This article looks at the issue — largely neglected in the transition literature — of the relative weights of the privatized sector and the generic private sector (of de novo private firms) in the emerging private sector of post-communist economies in transition. The present writer posits that the relative weight of each in the aggregate share of a private sector (generally expanding over time as transition progresses) strongly influences economic performance, both during correctional recession and during recovery and expansion period. Another, interrelated issue considered here is the interaction between the evolving institutional framework and the expansion of the generic private sector, that is the most dynamic one in the transition economy. It is true that the interaction between institutions and performance has been a staple of a very large number of books, articles, and papers.&lt;/jats:p&gt;\\n               &lt;jats:p&gt;However, this article concentrates on one component of a private sector only, that is the generic private sector. But at the same time it looks beyond the ‘Holy Trinity’ of transition (stabilization, liberalization, and privatization) towards a wider institutional framework of political liberty, law and order. The foregoing wider framework, and the emerging general trust, matters as much — if not more — for the present writer as the standard transition program.&lt;/jats:p&gt;\\n               &lt;jats:p&gt;It is the relative dynamics of both components of the private sector, affected by both standard transition programs and the above-mentioned wider institutional framework, that is of primary importance for the economic performance in post-communist transition. In the last part of the article I will try also to answer, tentatively, the question under which circumstances the wider institutional framework may emerge in the transition process.&lt;/jats:p&gt;</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80280</th>\n",
       "      <td>&lt;jats:title&gt;Summary&lt;/jats:title&gt;&lt;jats:p&gt;There have been previous suggestions in the literature of a link between schizophrenia and retinitis pigmentosa (RP) or its associated syndromes. In this article, we describe two cases of schizophrenía and two cases of delusional disorder occurring in patients with RP. We explore possible reasons for an association between RP and schizophrenia including shared genetic predisposition, sensory deprivation, coarse brain disease and retinoid dysregulation. Awareness of an association may help to direct future research into the aetiology of these disorders, especially in the areas of neurochemistry and medical genetics.&lt;/jats:p&gt;</td>\n",
       "      <td>-0.010811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80281 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      abstract  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <jats:title>Abstract</jats:title><jats:p>The photolysis of dilute solutions of octacyclosulphur or hexacyclosulphur in n-hexane with 253.6 nm UV radiation produces S and possibly S<jats:sub>2</jats:sub>. The ‘ring-opening’ yields of these sulphur molecules range from 0.2 to 0.7. When the hydrogen end-capped polyyne C<jats:sub>10</jats:sub>H<jats:sub>2</jats:sub> is irradiated in n-hexane, it transforms into unidentified products with a quantum yield of 3×10<jats:sup>−5</jats:sup>. When octacyclosulphur is added to the solution, the yield rises to 7×10<jats:sup>−3</jats:sup>. The putative sulphur-bearing product(s) could not be identified. It is suggested that sulphur-bearing molecules might be formed in astronomical settings by reactions of carbon molecules having triple or double C—C bonds with photolytically produced S and/or S<jats:sub>2</jats:sub>.</jats:p>   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 <jats:title>Abstract</jats:title><jats:p>Examples are given of unforeseen damage or difficulties arising during or after construction of buildings, wharves, foundations, tunnels, in-ground storage, pipe lines, and embankments. The underlying potentially latent mechanisms of groundwater are classified into four groups, namely water pressure changes, physical changes, erosion, and affects of earthworks, in order to assist early identification of some of the types of change in ground properties which may be induced by site operations and may lead to damage. It is concluded that otherwise unforeseen damage is more likely to be averted by a greater degree of investigation during construction into the consequences of the construction sequences, method and plant used.</jats:p>   \n",
       "2                                                                                 <jats:p> Acute hypoxia causes pulmonary vasoconstriction and coronary vasodilation. The divergent effects of hypoxia on pulmonary and coronary vascular smooth muscle cells suggest that the mechanisms involved in oxygen sensing and downstream effectors are different in these two types of cells. Since production of reactive oxygen species (ROS) is regulated by oxygen tension, ROS have been hypothesized to be a signaling mechanism in hypoxia-induced pulmonary vasoconstriction and vascular remodeling. Furthermore, an increased ROS production is also implicated in arteriosclerosis. In this study, we determined and compared the effects of hypoxia on ROS levels in human pulmonary arterial smooth muscle cells (PASMC) and coronary arterial smooth muscle cells (CASMC). Our results indicated that acute exposure to hypoxia (Po<jats:sub>2</jats:sub> = 25–30 mmHg for 5–10 min) significantly and rapidly decreased ROS levels in both PASMC and CASMC. However, chronic exposure to hypoxia (Po<jats:sub>2</jats:sub> = 30 mmHg for 48 h) markedly increased ROS levels in PASMC, but decreased ROS production in CASMC. Furthermore, chronic treatment with endothelin-1, a potent vasoconstrictor and mitogen, caused a significant increase in ROS production in both PASMC and CASMC. The inhibitory effect of acute hypoxia on ROS production in PASMC was also accelerated in cells chronically treated with endothelin-1. While the decreased ROS in PASMC and CASMC after acute exposure to hypoxia may reflect the lower level of oxygen substrate available for ROS production, the increased ROS production in PASMC during chronic hypoxia may reflect a pathophysiological response unique to the pulmonary vasculature that contributes to the development of pulmonary vascular remodeling in patients with hypoxia-associated pulmonary hypertension. </jats:p>   \n",
       "3      <jats:title>Abstract</jats:title>\\n               <jats:p>Despite rapid advances in the stem cell field, the ability to identify and track transplanted or migrating stem cells in vivo is limited. To overcome this limitation, we used magnetic resonance imaging (MRI) to detect and follow transplanted stem cells over a period of 28 days in mice using an established myocardial infarction model. Pluripotent mouse embryonic stem (mES) cells were expanded and induced to differentiate into beating cardiomyocytes in vitro. The cardiac-differentiated mES cells were then loaded with superparamagnetic fluorescent microspheres (1.63 μm in diameter) and transplanted into ischemic myocardium immediately following ligation and subsequent reperfusion of the left anterior descending coronary artery. To identify the transplanted stem cells in vivo, MRI was performed using a Varian Inova 4.7 Tesla scanner. Our results show that (a) the cardiac-differentiated mES were effectively loaded with superparamagnetic microspheres in vitro, (b) the microsphere-loaded mES cells continued to beat in culture prior to transplantation, (c) the transplanted mES cells were readily detected in the heart in vivo using noninvasive MRI techniques, (d) the transplanted stem cells were detected in ischemic myocardium for the entire 28-day duration of the study as confirmed by MRI and post-mortem histological analyses, and (e) concurrent functional MRI indicated typical loss of cardiac function, although significant amelioration of remodeling was noted after 28 days in hearts that received transplanted stem cells. These results demonstrate that it is feasible to simultaneously track transplanted stem cells and monitor cardiac function in vivo over an extended period using noninvasive MRI techniques.</jats:p>\\n               <jats:p>Disclosure of potential conflicts of interest is found at the end of this article.</jats:p>   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <jats:title>Abstract</jats:title>\\n               <jats:p>For the regenerative therapy of osteochondral defects – deep lesions of the articular cartilage in which the underlying bone tissue is already affected too – special implant materials and scaffolds are needed. In this study, two new approaches will be presented, leading to biphasic, but monolithic scaffold materials. Both consist of a mineralised layer for filling of the bony part of the defect and a non-mineralised one for the chondral part. Due to the preparation methods, both layers are fused together to give a unified whole without need of any artificial joining. The resulting materials, either based on collagen, hyaluronic acid and hydroxyapatite or calcium alginate gels and hydroxyapatite, seem to be suitable scaffolds for cultivating chondrocytes and osteoblasts – and therefore can act as matrices for tissue engineering of osteochondral grafts.</jats:p>   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ...   \n",
       "80276                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <jats:p>The nymphal instars I and III - V of Sigara (Tropocorixa) denseconscripta (Breddin, 1897) are figured and described in detail, for the first time, with emphasis on morphometry and chaetotaxy of selected structures. The useful characters to identify the nymphal instars and the nymphs of the species of Sigara are provided.</jats:p>   \n",
       "80277                                      <jats:p> The possible effects of a wide range of sociodemographic and environmental factors on the incidence and distribution of petechiae were investigated in 485 sudden infant death syndrome (SIDS) cases from the New Zealand Cot Death Study. The number (nil, few, many) of macroscopic petechial hemorrhages in the visceral pleura, capsule of thymus, and epicardium was recorded in 458 of 474 autopsied SIDS cases. Other information was obtained from parental interview and obstetric records. Univariate analysis showed highly significant relationships ( P ≤ 0.005) between the frequency of petechiae at one or more sites and socioeconomic status, parity, breast feeding, age at death, time of death, sleep position, and head covering at death and lesser but significant relationships ( P ≤ 0.05) with Maori ethnicity, birth weight, gestation, pacifier use, and bed sharing. After multivariate analysis, significant associations remained between increased frequencies of thymic petechiae and parity (P = 0.0001), age at death (P = 0.0003), Maori ethnicity (P = 0.0019), pacifier use (P = 0.0001), and head covering at death (P = 0.0032); between increased frequencies of epicardial petechiae and head covering at death (P = 0.008) and an estimated time of death between 00:00 and 05:59 h ( P = 0.056); and between increased frequencies of pleural petechiae and maternal smoking ( P = 0.058) and parity ( P = 0.022). There was a decreased frequency of pleural petechiae in infants placed prone for their final sleep ( P = 0.058). The distribution and frequency of petechiae are affected by environmental factors, including known risk factors for SIDS, but these factors occur inconsistently across the three sites. The findings imply differences in the pathogenesis at each site but do not provide consistent support for previous theories of causation of petechiae. </jats:p>   \n",
       "80278                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <jats:p>After electroconvulsive therapy (ECT), many patients experience a decrement in their mnestic capacity. We studied episodic memory in eight severely depressed patients treated with a course of right-unilateral ECT. For this purpose, a testing instrument was constructed by the authors. It was made of paper cards that held four pieces of information, namely a word, a number, a figure, and the color of the card. One of the cards was presented to the patients and the respective information was asked for on the subsequent day. Patients were tested every morning during the first two weeks of the ECT course. About half of the responses were correct. Patients did best in recalling the color; they did worst in recalling the number. Seven of the patients showed verbal perseverations. This is in accordance with the literature on perseveration in patients with neurologic deficits, especially in proactive-inhibitory tasks. Perseveration may be attributed to a deficit in selective attention, producing an arousal of irrelevant cues.</jats:p>   \n",
       "80279                         <jats:p>This article looks at the issue — largely neglected in the transition literature — of the relative weights of the privatized sector and the generic private sector (of de novo private firms) in the emerging private sector of post-communist economies in transition. The present writer posits that the relative weight of each in the aggregate share of a private sector (generally expanding over time as transition progresses) strongly influences economic performance, both during correctional recession and during recovery and expansion period. Another, interrelated issue considered here is the interaction between the evolving institutional framework and the expansion of the generic private sector, that is the most dynamic one in the transition economy. It is true that the interaction between institutions and performance has been a staple of a very large number of books, articles, and papers.</jats:p>\\n               <jats:p>However, this article concentrates on one component of a private sector only, that is the generic private sector. But at the same time it looks beyond the ‘Holy Trinity’ of transition (stabilization, liberalization, and privatization) towards a wider institutional framework of political liberty, law and order. The foregoing wider framework, and the emerging general trust, matters as much — if not more — for the present writer as the standard transition program.</jats:p>\\n               <jats:p>It is the relative dynamics of both components of the private sector, affected by both standard transition programs and the above-mentioned wider institutional framework, that is of primary importance for the economic performance in post-communist transition. In the last part of the article I will try also to answer, tentatively, the question under which circumstances the wider institutional framework may emerge in the transition process.</jats:p>   \n",
       "80280                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          <jats:title>Summary</jats:title><jats:p>There have been previous suggestions in the literature of a link between schizophrenia and retinitis pigmentosa (RP) or its associated syndromes. In this article, we describe two cases of schizophrenía and two cases of delusional disorder occurring in patients with RP. We explore possible reasons for an association between RP and schizophrenia including shared genetic predisposition, sensory deprivation, coarse brain disease and retinoid dysregulation. Awareness of an association may help to direct future research into the aetiology of these disorders, especially in the areas of neurochemistry and medical genetics.</jats:p>   \n",
       "\n",
       "        cdindex  \n",
       "0      0.000000  \n",
       "1      0.000000  \n",
       "2     -0.002938  \n",
       "3     -0.004497  \n",
       "4     -0.004373  \n",
       "...         ...  \n",
       "80276 -0.100000  \n",
       "80277 -0.007576  \n",
       "80278 -0.040000  \n",
       "80279  0.100000  \n",
       "80280 -0.010811  \n",
       "\n",
       "[80281 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_query('SELECT abstract, cdindex FROM data', connection)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We detect that the data have a format where like typical html code we have\n",
    "\n",
    "< lorem ipsum >Lorem Ipsum < /lorem ipsum >.\n",
    "\n",
    "So we clear all the < > while keeping the whitespace between words and remove the word 'Abstact' that some rows have as a first word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     The photolysis of dilute solutions of octacyclosulphur or hexacyclosulphur in n-hexane with 253.6 nm UV radiation produces S and possibly S2. The ‘ring-opening’ yields of these sulphur molecules range from 0.2 to 0.7. When the hydrogen end-capped polyyne C10H2 is irradiated in n-hexane, it transforms into unidentified products with a quantum yield of 3×10−5. When octacyclosulphur is added to the solution, the yield rises to 7×10−3. The putative sulphur-bearing product(s) could not be identified. It is suggested that sulphur-bearing molecules might be formed in astronomical settings by reactions of carbon molecules having triple or double C—C bonds with photolytically produced S and/or S2.\n",
       "1    Examples are given of unforeseen damage or difficulties arising during or after construction of buildings, wharves, foundations, tunnels, in-ground storage, pipe lines, and embankments. The underlying potentially latent mechanisms of groundwater are classified into four groups, namely water pressure changes, physical changes, erosion, and affects of earthworks, in order to assist early identification of some of the types of change in ground properties which may be induced by site operations and may lead to damage. It is concluded that otherwise unforeseen damage is more likely to be averted by a greater degree of investigation during construction into the consequences of the construction sequences, method and plant used.\n",
       "Name: abstract, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['abstract'] = df['abstract'].apply(lambda x: re.sub('<.*?>', '', x).replace('Abstract', '').strip())\n",
    "df['abstract'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>cdindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The photolysis of dilute solutions of octacyclosulphur or hexacyclosulphur in n-hexane with 253.6 nm UV radiation produces S and possibly S2. The ‘ring-opening’ yields of these sulphur molecules range from 0.2 to 0.7. When the hydrogen end-capped polyyne C10H2 is irradiated in n-hexane, it transforms into unidentified products with a quantum yield of 3×10−5. When octacyclosulphur is added to the solution, the yield rises to 7×10−3. The putative sulphur-bearing product(s) could not be identified. It is suggested that sulphur-bearing molecules might be formed in astronomical settings by reactions of carbon molecules having triple or double C—C bonds with photolytically produced S and/or S2.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Examples are given of unforeseen damage or difficulties arising during or after construction of buildings, wharves, foundations, tunnels, in-ground storage, pipe lines, and embankments. The underlying potentially latent mechanisms of groundwater are classified into four groups, namely water pressure changes, physical changes, erosion, and affects of earthworks, in order to assist early identification of some of the types of change in ground properties which may be induced by site operations and may lead to damage. It is concluded that otherwise unforeseen damage is more likely to be averted by a greater degree of investigation during construction into the consequences of the construction sequences, method and plant used.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acute hypoxia causes pulmonary vasoconstriction and coronary vasodilation. The divergent effects of hypoxia on pulmonary and coronary vascular smooth muscle cells suggest that the mechanisms involved in oxygen sensing and downstream effectors are different in these two types of cells. Since production of reactive oxygen species (ROS) is regulated by oxygen tension, ROS have been hypothesized to be a signaling mechanism in hypoxia-induced pulmonary vasoconstriction and vascular remodeling. Furthermore, an increased ROS production is also implicated in arteriosclerosis. In this study, we determined and compared the effects of hypoxia on ROS levels in human pulmonary arterial smooth muscle cells (PASMC) and coronary arterial smooth muscle cells (CASMC). Our results indicated that acute exposure to hypoxia (Po2 = 25–30 mmHg for 5–10 min) significantly and rapidly decreased ROS levels in both PASMC and CASMC. However, chronic exposure to hypoxia (Po2 = 30 mmHg for 48 h) markedly increased ROS levels in PASMC, but decreased ROS production in CASMC. Furthermore, chronic treatment with endothelin-1, a potent vasoconstrictor and mitogen, caused a significant increase in ROS production in both PASMC and CASMC. The inhibitory effect of acute hypoxia on ROS production in PASMC was also accelerated in cells chronically treated with endothelin-1. While the decreased ROS in PASMC and CASMC after acute exposure to hypoxia may reflect the lower level of oxygen substrate available for ROS production, the increased ROS production in PASMC during chronic hypoxia may reflect a pathophysiological response unique to the pulmonary vasculature that contributes to the development of pulmonary vascular remodeling in patients with hypoxia-associated pulmonary hypertension.</td>\n",
       "      <td>-0.002938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Despite rapid advances in the stem cell field, the ability to identify and track transplanted or migrating stem cells in vivo is limited. To overcome this limitation, we used magnetic resonance imaging (MRI) to detect and follow transplanted stem cells over a period of 28 days in mice using an established myocardial infarction model. Pluripotent mouse embryonic stem (mES) cells were expanded and induced to differentiate into beating cardiomyocytes in vitro. The cardiac-differentiated mES cells were then loaded with superparamagnetic fluorescent microspheres (1.63 μm in diameter) and transplanted into ischemic myocardium immediately following ligation and subsequent reperfusion of the left anterior descending coronary artery. To identify the transplanted stem cells in vivo, MRI was performed using a Varian Inova 4.7 Tesla scanner. Our results show that (a) the cardiac-differentiated mES were effectively loaded with superparamagnetic microspheres in vitro, (b) the microsphere-loaded mES cells continued to beat in culture prior to transplantation, (c) the transplanted mES cells were readily detected in the heart in vivo using noninvasive MRI techniques, (d) the transplanted stem cells were detected in ischemic myocardium for the entire 28-day duration of the study as confirmed by MRI and post-mortem histological analyses, and (e) concurrent functional MRI indicated typical loss of cardiac function, although significant amelioration of remodeling was noted after 28 days in hearts that received transplanted stem cells. These results demonstrate that it is feasible to simultaneously track transplanted stem cells and monitor cardiac function in vivo over an extended period using noninvasive MRI techniques.\\n               Disclosure of potential conflicts of interest is found at the end of this article.</td>\n",
       "      <td>-0.004497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For the regenerative therapy of osteochondral defects – deep lesions of the articular cartilage in which the underlying bone tissue is already affected too – special implant materials and scaffolds are needed. In this study, two new approaches will be presented, leading to biphasic, but monolithic scaffold materials. Both consist of a mineralised layer for filling of the bony part of the defect and a non-mineralised one for the chondral part. Due to the preparation methods, both layers are fused together to give a unified whole without need of any artificial joining. The resulting materials, either based on collagen, hyaluronic acid and hydroxyapatite or calcium alginate gels and hydroxyapatite, seem to be suitable scaffolds for cultivating chondrocytes and osteoblasts – and therefore can act as matrices for tissue engineering of osteochondral grafts.</td>\n",
       "      <td>-0.004373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80276</th>\n",
       "      <td>The nymphal instars I and III - V of Sigara (Tropocorixa) denseconscripta (Breddin, 1897) are figured and described in detail, for the first time, with emphasis on morphometry and chaetotaxy of selected structures. The useful characters to identify the nymphal instars and the nymphs of the species of Sigara are provided.</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80277</th>\n",
       "      <td>The possible effects of a wide range of sociodemographic and environmental factors on the incidence and distribution of petechiae were investigated in 485 sudden infant death syndrome (SIDS) cases from the New Zealand Cot Death Study. The number (nil, few, many) of macroscopic petechial hemorrhages in the visceral pleura, capsule of thymus, and epicardium was recorded in 458 of 474 autopsied SIDS cases. Other information was obtained from parental interview and obstetric records. Univariate analysis showed highly significant relationships ( P ≤ 0.005) between the frequency of petechiae at one or more sites and socioeconomic status, parity, breast feeding, age at death, time of death, sleep position, and head covering at death and lesser but significant relationships ( P ≤ 0.05) with Maori ethnicity, birth weight, gestation, pacifier use, and bed sharing. After multivariate analysis, significant associations remained between increased frequencies of thymic petechiae and parity (P = 0.0001), age at death (P = 0.0003), Maori ethnicity (P = 0.0019), pacifier use (P = 0.0001), and head covering at death (P = 0.0032); between increased frequencies of epicardial petechiae and head covering at death (P = 0.008) and an estimated time of death between 00:00 and 05:59 h ( P = 0.056); and between increased frequencies of pleural petechiae and maternal smoking ( P = 0.058) and parity ( P = 0.022). There was a decreased frequency of pleural petechiae in infants placed prone for their final sleep ( P = 0.058). The distribution and frequency of petechiae are affected by environmental factors, including known risk factors for SIDS, but these factors occur inconsistently across the three sites. The findings imply differences in the pathogenesis at each site but do not provide consistent support for previous theories of causation of petechiae.</td>\n",
       "      <td>-0.007576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80278</th>\n",
       "      <td>After electroconvulsive therapy (ECT), many patients experience a decrement in their mnestic capacity. We studied episodic memory in eight severely depressed patients treated with a course of right-unilateral ECT. For this purpose, a testing instrument was constructed by the authors. It was made of paper cards that held four pieces of information, namely a word, a number, a figure, and the color of the card. One of the cards was presented to the patients and the respective information was asked for on the subsequent day. Patients were tested every morning during the first two weeks of the ECT course. About half of the responses were correct. Patients did best in recalling the color; they did worst in recalling the number. Seven of the patients showed verbal perseverations. This is in accordance with the literature on perseveration in patients with neurologic deficits, especially in proactive-inhibitory tasks. Perseveration may be attributed to a deficit in selective attention, producing an arousal of irrelevant cues.</td>\n",
       "      <td>-0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80279</th>\n",
       "      <td>This article looks at the issue — largely neglected in the transition literature — of the relative weights of the privatized sector and the generic private sector (of de novo private firms) in the emerging private sector of post-communist economies in transition. The present writer posits that the relative weight of each in the aggregate share of a private sector (generally expanding over time as transition progresses) strongly influences economic performance, both during correctional recession and during recovery and expansion period. Another, interrelated issue considered here is the interaction between the evolving institutional framework and the expansion of the generic private sector, that is the most dynamic one in the transition economy. It is true that the interaction between institutions and performance has been a staple of a very large number of books, articles, and papers.\\n               However, this article concentrates on one component of a private sector only, that is the generic private sector. But at the same time it looks beyond the ‘Holy Trinity’ of transition (stabilization, liberalization, and privatization) towards a wider institutional framework of political liberty, law and order. The foregoing wider framework, and the emerging general trust, matters as much — if not more — for the present writer as the standard transition program.\\n               It is the relative dynamics of both components of the private sector, affected by both standard transition programs and the above-mentioned wider institutional framework, that is of primary importance for the economic performance in post-communist transition. In the last part of the article I will try also to answer, tentatively, the question under which circumstances the wider institutional framework may emerge in the transition process.</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80280</th>\n",
       "      <td>SummaryThere have been previous suggestions in the literature of a link between schizophrenia and retinitis pigmentosa (RP) or its associated syndromes. In this article, we describe two cases of schizophrenía and two cases of delusional disorder occurring in patients with RP. We explore possible reasons for an association between RP and schizophrenia including shared genetic predisposition, sensory deprivation, coarse brain disease and retinoid dysregulation. Awareness of an association may help to direct future research into the aetiology of these disorders, especially in the areas of neurochemistry and medical genetics.</td>\n",
       "      <td>-0.010811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80281 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               abstract  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             The photolysis of dilute solutions of octacyclosulphur or hexacyclosulphur in n-hexane with 253.6 nm UV radiation produces S and possibly S2. The ‘ring-opening’ yields of these sulphur molecules range from 0.2 to 0.7. When the hydrogen end-capped polyyne C10H2 is irradiated in n-hexane, it transforms into unidentified products with a quantum yield of 3×10−5. When octacyclosulphur is added to the solution, the yield rises to 7×10−3. The putative sulphur-bearing product(s) could not be identified. It is suggested that sulphur-bearing molecules might be formed in astronomical settings by reactions of carbon molecules having triple or double C—C bonds with photolytically produced S and/or S2.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Examples are given of unforeseen damage or difficulties arising during or after construction of buildings, wharves, foundations, tunnels, in-ground storage, pipe lines, and embankments. The underlying potentially latent mechanisms of groundwater are classified into four groups, namely water pressure changes, physical changes, erosion, and affects of earthworks, in order to assist early identification of some of the types of change in ground properties which may be induced by site operations and may lead to damage. It is concluded that otherwise unforeseen damage is more likely to be averted by a greater degree of investigation during construction into the consequences of the construction sequences, method and plant used.   \n",
       "2                                                                                       Acute hypoxia causes pulmonary vasoconstriction and coronary vasodilation. The divergent effects of hypoxia on pulmonary and coronary vascular smooth muscle cells suggest that the mechanisms involved in oxygen sensing and downstream effectors are different in these two types of cells. Since production of reactive oxygen species (ROS) is regulated by oxygen tension, ROS have been hypothesized to be a signaling mechanism in hypoxia-induced pulmonary vasoconstriction and vascular remodeling. Furthermore, an increased ROS production is also implicated in arteriosclerosis. In this study, we determined and compared the effects of hypoxia on ROS levels in human pulmonary arterial smooth muscle cells (PASMC) and coronary arterial smooth muscle cells (CASMC). Our results indicated that acute exposure to hypoxia (Po2 = 25–30 mmHg for 5–10 min) significantly and rapidly decreased ROS levels in both PASMC and CASMC. However, chronic exposure to hypoxia (Po2 = 30 mmHg for 48 h) markedly increased ROS levels in PASMC, but decreased ROS production in CASMC. Furthermore, chronic treatment with endothelin-1, a potent vasoconstrictor and mitogen, caused a significant increase in ROS production in both PASMC and CASMC. The inhibitory effect of acute hypoxia on ROS production in PASMC was also accelerated in cells chronically treated with endothelin-1. While the decreased ROS in PASMC and CASMC after acute exposure to hypoxia may reflect the lower level of oxygen substrate available for ROS production, the increased ROS production in PASMC during chronic hypoxia may reflect a pathophysiological response unique to the pulmonary vasculature that contributes to the development of pulmonary vascular remodeling in patients with hypoxia-associated pulmonary hypertension.   \n",
       "3                                   Despite rapid advances in the stem cell field, the ability to identify and track transplanted or migrating stem cells in vivo is limited. To overcome this limitation, we used magnetic resonance imaging (MRI) to detect and follow transplanted stem cells over a period of 28 days in mice using an established myocardial infarction model. Pluripotent mouse embryonic stem (mES) cells were expanded and induced to differentiate into beating cardiomyocytes in vitro. The cardiac-differentiated mES cells were then loaded with superparamagnetic fluorescent microspheres (1.63 μm in diameter) and transplanted into ischemic myocardium immediately following ligation and subsequent reperfusion of the left anterior descending coronary artery. To identify the transplanted stem cells in vivo, MRI was performed using a Varian Inova 4.7 Tesla scanner. Our results show that (a) the cardiac-differentiated mES were effectively loaded with superparamagnetic microspheres in vitro, (b) the microsphere-loaded mES cells continued to beat in culture prior to transplantation, (c) the transplanted mES cells were readily detected in the heart in vivo using noninvasive MRI techniques, (d) the transplanted stem cells were detected in ischemic myocardium for the entire 28-day duration of the study as confirmed by MRI and post-mortem histological analyses, and (e) concurrent functional MRI indicated typical loss of cardiac function, although significant amelioration of remodeling was noted after 28 days in hearts that received transplanted stem cells. These results demonstrate that it is feasible to simultaneously track transplanted stem cells and monitor cardiac function in vivo over an extended period using noninvasive MRI techniques.\\n               Disclosure of potential conflicts of interest is found at the end of this article.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       For the regenerative therapy of osteochondral defects – deep lesions of the articular cartilage in which the underlying bone tissue is already affected too – special implant materials and scaffolds are needed. In this study, two new approaches will be presented, leading to biphasic, but monolithic scaffold materials. Both consist of a mineralised layer for filling of the bony part of the defect and a non-mineralised one for the chondral part. Due to the preparation methods, both layers are fused together to give a unified whole without need of any artificial joining. The resulting materials, either based on collagen, hyaluronic acid and hydroxyapatite or calcium alginate gels and hydroxyapatite, seem to be suitable scaffolds for cultivating chondrocytes and osteoblasts – and therefore can act as matrices for tissue engineering of osteochondral grafts.   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ...   \n",
       "80276                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The nymphal instars I and III - V of Sigara (Tropocorixa) denseconscripta (Breddin, 1897) are figured and described in detail, for the first time, with emphasis on morphometry and chaetotaxy of selected structures. The useful characters to identify the nymphal instars and the nymphs of the species of Sigara are provided.   \n",
       "80277  The possible effects of a wide range of sociodemographic and environmental factors on the incidence and distribution of petechiae were investigated in 485 sudden infant death syndrome (SIDS) cases from the New Zealand Cot Death Study. The number (nil, few, many) of macroscopic petechial hemorrhages in the visceral pleura, capsule of thymus, and epicardium was recorded in 458 of 474 autopsied SIDS cases. Other information was obtained from parental interview and obstetric records. Univariate analysis showed highly significant relationships ( P ≤ 0.005) between the frequency of petechiae at one or more sites and socioeconomic status, parity, breast feeding, age at death, time of death, sleep position, and head covering at death and lesser but significant relationships ( P ≤ 0.05) with Maori ethnicity, birth weight, gestation, pacifier use, and bed sharing. After multivariate analysis, significant associations remained between increased frequencies of thymic petechiae and parity (P = 0.0001), age at death (P = 0.0003), Maori ethnicity (P = 0.0019), pacifier use (P = 0.0001), and head covering at death (P = 0.0032); between increased frequencies of epicardial petechiae and head covering at death (P = 0.008) and an estimated time of death between 00:00 and 05:59 h ( P = 0.056); and between increased frequencies of pleural petechiae and maternal smoking ( P = 0.058) and parity ( P = 0.022). There was a decreased frequency of pleural petechiae in infants placed prone for their final sleep ( P = 0.058). The distribution and frequency of petechiae are affected by environmental factors, including known risk factors for SIDS, but these factors occur inconsistently across the three sites. The findings imply differences in the pathogenesis at each site but do not provide consistent support for previous theories of causation of petechiae.   \n",
       "80278                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          After electroconvulsive therapy (ECT), many patients experience a decrement in their mnestic capacity. We studied episodic memory in eight severely depressed patients treated with a course of right-unilateral ECT. For this purpose, a testing instrument was constructed by the authors. It was made of paper cards that held four pieces of information, namely a word, a number, a figure, and the color of the card. One of the cards was presented to the patients and the respective information was asked for on the subsequent day. Patients were tested every morning during the first two weeks of the ECT course. About half of the responses were correct. Patients did best in recalling the color; they did worst in recalling the number. Seven of the patients showed verbal perseverations. This is in accordance with the literature on perseveration in patients with neurologic deficits, especially in proactive-inhibitory tasks. Perseveration may be attributed to a deficit in selective attention, producing an arousal of irrelevant cues.   \n",
       "80279                     This article looks at the issue — largely neglected in the transition literature — of the relative weights of the privatized sector and the generic private sector (of de novo private firms) in the emerging private sector of post-communist economies in transition. The present writer posits that the relative weight of each in the aggregate share of a private sector (generally expanding over time as transition progresses) strongly influences economic performance, both during correctional recession and during recovery and expansion period. Another, interrelated issue considered here is the interaction between the evolving institutional framework and the expansion of the generic private sector, that is the most dynamic one in the transition economy. It is true that the interaction between institutions and performance has been a staple of a very large number of books, articles, and papers.\\n               However, this article concentrates on one component of a private sector only, that is the generic private sector. But at the same time it looks beyond the ‘Holy Trinity’ of transition (stabilization, liberalization, and privatization) towards a wider institutional framework of political liberty, law and order. The foregoing wider framework, and the emerging general trust, matters as much — if not more — for the present writer as the standard transition program.\\n               It is the relative dynamics of both components of the private sector, affected by both standard transition programs and the above-mentioned wider institutional framework, that is of primary importance for the economic performance in post-communist transition. In the last part of the article I will try also to answer, tentatively, the question under which circumstances the wider institutional framework may emerge in the transition process.   \n",
       "80280                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             SummaryThere have been previous suggestions in the literature of a link between schizophrenia and retinitis pigmentosa (RP) or its associated syndromes. In this article, we describe two cases of schizophrenía and two cases of delusional disorder occurring in patients with RP. We explore possible reasons for an association between RP and schizophrenia including shared genetic predisposition, sensory deprivation, coarse brain disease and retinoid dysregulation. Awareness of an association may help to direct future research into the aetiology of these disorders, especially in the areas of neurochemistry and medical genetics.   \n",
       "\n",
       "        cdindex  \n",
       "0      0.000000  \n",
       "1      0.000000  \n",
       "2     -0.002938  \n",
       "3     -0.004497  \n",
       "4     -0.004373  \n",
       "...         ...  \n",
       "80276 -0.100000  \n",
       "80277 -0.007576  \n",
       "80278 -0.040000  \n",
       "80279  0.100000  \n",
       "80280 -0.010811  \n",
       "\n",
       "[80281 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sup = pd.read_csv('data/data.csv')\n",
    "df_sup.drop(columns='Unnamed: 0', inplace=True)\n",
    "df_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>cdindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the photolysis of dilute solutions of octacyclosulphur or hexacyclosulphur in n-hexane with 253.6 nm uv radiation produces s and possibly s2. the ‘ring-opening’ yields of these sulphur molecules range from 0.2 to 0.7. when the hydrogen end-capped polyyne c10h2 is irradiated in n-hexane, it transforms into unidentified products with a quantum yield of 3×10−5. when octacyclosulphur is added to the solution, the yield rises to 7×10−3. the putative sulphur-bearing product(s) could not be identified. it is suggested that sulphur-bearing molecules might be formed in astronomical settings by reactions of carbon molecules having triple or double c—c bonds with photolytically produced s and/or s2.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>examples are given of unforeseen damage or difficulties arising during or after construction of buildings, wharves, foundations, tunnels, in-ground storage, pipe lines, and embankments. the underlying potentially latent mechanisms of groundwater are classified into four groups, namely water pressure changes, physical changes, erosion, and affects of earthworks, in order to assist early identification of some of the types of change in ground properties which may be induced by site operations and may lead to damage. it is concluded that otherwise unforeseen damage is more likely to be averted by a greater degree of investigation during construction into the consequences of the construction sequences, method and plant used.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acute hypoxia causes pulmonary vasoconstriction and coronary vasodilation. the divergent effects of hypoxia on pulmonary and coronary vascular smooth muscle cells suggest that the mechanisms involved in oxygen sensing and downstream effectors are different in these two types of cells. since production of reactive oxygen species (ros) is regulated by oxygen tension, ros have been hypothesized to be a signaling mechanism in hypoxia-induced pulmonary vasoconstriction and vascular remodeling. furthermore, an increased ros production is also implicated in arteriosclerosis. in this study, we determined and compared the effects of hypoxia on ros levels in human pulmonary arterial smooth muscle cells (pasmc) and coronary arterial smooth muscle cells (casmc). our results indicated that acute exposure to hypoxia (po2 = 25–30 mmhg for 5–10 min) significantly and rapidly decreased ros levels in both pasmc and casmc. however, chronic exposure to hypoxia (po2 = 30 mmhg for 48 h) markedly increased ros levels in pasmc, but decreased ros production in casmc. furthermore, chronic treatment with endothelin-1, a potent vasoconstrictor and mitogen, caused a significant increase in ros production in both pasmc and casmc. the inhibitory effect of acute hypoxia on ros production in pasmc was also accelerated in cells chronically treated with endothelin-1. while the decreased ros in pasmc and casmc after acute exposure to hypoxia may reflect the lower level of oxygen substrate available for ros production, the increased ros production in pasmc during chronic hypoxia may reflect a pathophysiological response unique to the pulmonary vasculature that contributes to the development of pulmonary vascular remodeling in patients with hypoxia-associated pulmonary hypertension.</td>\n",
       "      <td>-0.002938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>despite rapid advances in the stem cell field, the ability to identify and track transplanted or migrating stem cells in vivo is limited. to overcome this limitation, we used magnetic resonance imaging (mri) to detect and follow transplanted stem cells over a period of 28 days in mice using an established myocardial infarction model. pluripotent mouse embryonic stem (mes) cells were expanded and induced to differentiate into beating cardiomyocytes in vitro. the cardiac-differentiated mes cells were then loaded with superparamagnetic fluorescent microspheres (1.63 μm in diameter) and transplanted into ischemic myocardium immediately following ligation and subsequent reperfusion of the left anterior descending coronary artery. to identify the transplanted stem cells in vivo, mri was performed using a varian inova 4.7 tesla scanner. our results show that (a) the cardiac-differentiated mes were effectively loaded with superparamagnetic microspheres in vitro, (b) the microsphere-loaded mes cells continued to beat in culture prior to transplantation, (c) the transplanted mes cells were readily detected in the heart in vivo using noninvasive mri techniques, (d) the transplanted stem cells were detected in ischemic myocardium for the entire 28-day duration of the study as confirmed by mri and post-mortem histological analyses, and (e) concurrent functional mri indicated typical loss of cardiac function, although significant amelioration of remodeling was noted after 28 days in hearts that received transplanted stem cells. these results demonstrate that it is feasible to simultaneously track transplanted stem cells and monitor cardiac function in vivo over an extended period using noninvasive mri techniques.\\n               disclosure of potential conflicts of interest is found at the end of this article.</td>\n",
       "      <td>-0.004497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for the regenerative therapy of osteochondral defects – deep lesions of the articular cartilage in which the underlying bone tissue is already affected too – special implant materials and scaffolds are needed. in this study, two new approaches will be presented, leading to biphasic, but monolithic scaffold materials. both consist of a mineralised layer for filling of the bony part of the defect and a non-mineralised one for the chondral part. due to the preparation methods, both layers are fused together to give a unified whole without need of any artificial joining. the resulting materials, either based on collagen, hyaluronic acid and hydroxyapatite or calcium alginate gels and hydroxyapatite, seem to be suitable scaffolds for cultivating chondrocytes and osteoblasts – and therefore can act as matrices for tissue engineering of osteochondral grafts.</td>\n",
       "      <td>-0.004373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80276</th>\n",
       "      <td>the nymphal instars i and iii - v of sigara (tropocorixa) denseconscripta (breddin, 1897) are figured and described in detail, for the first time, with emphasis on morphometry and chaetotaxy of selected structures. the useful characters to identify the nymphal instars and the nymphs of the species of sigara are provided.</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80277</th>\n",
       "      <td>the possible effects of a wide range of sociodemographic and environmental factors on the incidence and distribution of petechiae were investigated in 485 sudden infant death syndrome (sids) cases from the new zealand cot death study. the number (nil, few, many) of macroscopic petechial hemorrhages in the visceral pleura, capsule of thymus, and epicardium was recorded in 458 of 474 autopsied sids cases. other information was obtained from parental interview and obstetric records. univariate analysis showed highly significant relationships ( p ≤ 0.005) between the frequency of petechiae at one or more sites and socioeconomic status, parity, breast feeding, age at death, time of death, sleep position, and head covering at death and lesser but significant relationships ( p ≤ 0.05) with maori ethnicity, birth weight, gestation, pacifier use, and bed sharing. after multivariate analysis, significant associations remained between increased frequencies of thymic petechiae and parity (p = 0.0001), age at death (p = 0.0003), maori ethnicity (p = 0.0019), pacifier use (p = 0.0001), and head covering at death (p = 0.0032); between increased frequencies of epicardial petechiae and head covering at death (p = 0.008) and an estimated time of death between 00:00 and 05:59 h ( p = 0.056); and between increased frequencies of pleural petechiae and maternal smoking ( p = 0.058) and parity ( p = 0.022). there was a decreased frequency of pleural petechiae in infants placed prone for their final sleep ( p = 0.058). the distribution and frequency of petechiae are affected by environmental factors, including known risk factors for sids, but these factors occur inconsistently across the three sites. the findings imply differences in the pathogenesis at each site but do not provide consistent support for previous theories of causation of petechiae.</td>\n",
       "      <td>-0.007576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80278</th>\n",
       "      <td>after electroconvulsive therapy (ect), many patients experience a decrement in their mnestic capacity. we studied episodic memory in eight severely depressed patients treated with a course of right-unilateral ect. for this purpose, a testing instrument was constructed by the authors. it was made of paper cards that held four pieces of information, namely a word, a number, a figure, and the color of the card. one of the cards was presented to the patients and the respective information was asked for on the subsequent day. patients were tested every morning during the first two weeks of the ect course. about half of the responses were correct. patients did best in recalling the color; they did worst in recalling the number. seven of the patients showed verbal perseverations. this is in accordance with the literature on perseveration in patients with neurologic deficits, especially in proactive-inhibitory tasks. perseveration may be attributed to a deficit in selective attention, producing an arousal of irrelevant cues.</td>\n",
       "      <td>-0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80279</th>\n",
       "      <td>this article looks at the issue — largely neglected in the transition literature — of the relative weights of the privatized sector and the generic private sector (of de novo private firms) in the emerging private sector of post-communist economies in transition. the present writer posits that the relative weight of each in the aggregate share of a private sector (generally expanding over time as transition progresses) strongly influences economic performance, both during correctional recession and during recovery and expansion period. another, interrelated issue considered here is the interaction between the evolving institutional framework and the expansion of the generic private sector, that is the most dynamic one in the transition economy. it is true that the interaction between institutions and performance has been a staple of a very large number of books, articles, and papers.\\n               however, this article concentrates on one component of a private sector only, that is the generic private sector. but at the same time it looks beyond the ‘holy trinity’ of transition (stabilization, liberalization, and privatization) towards a wider institutional framework of political liberty, law and order. the foregoing wider framework, and the emerging general trust, matters as much — if not more — for the present writer as the standard transition program.\\n               it is the relative dynamics of both components of the private sector, affected by both standard transition programs and the above-mentioned wider institutional framework, that is of primary importance for the economic performance in post-communist transition. in the last part of the article i will try also to answer, tentatively, the question under which circumstances the wider institutional framework may emerge in the transition process.</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80280</th>\n",
       "      <td>summarythere have been previous suggestions in the literature of a link between schizophrenia and retinitis pigmentosa (rp) or its associated syndromes. in this article, we describe two cases of schizophrenía and two cases of delusional disorder occurring in patients with rp. we explore possible reasons for an association between rp and schizophrenia including shared genetic predisposition, sensory deprivation, coarse brain disease and retinoid dysregulation. awareness of an association may help to direct future research into the aetiology of these disorders, especially in the areas of neurochemistry and medical genetics.</td>\n",
       "      <td>-0.010811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80281 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               abstract  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             the photolysis of dilute solutions of octacyclosulphur or hexacyclosulphur in n-hexane with 253.6 nm uv radiation produces s and possibly s2. the ‘ring-opening’ yields of these sulphur molecules range from 0.2 to 0.7. when the hydrogen end-capped polyyne c10h2 is irradiated in n-hexane, it transforms into unidentified products with a quantum yield of 3×10−5. when octacyclosulphur is added to the solution, the yield rises to 7×10−3. the putative sulphur-bearing product(s) could not be identified. it is suggested that sulphur-bearing molecules might be formed in astronomical settings by reactions of carbon molecules having triple or double c—c bonds with photolytically produced s and/or s2.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            examples are given of unforeseen damage or difficulties arising during or after construction of buildings, wharves, foundations, tunnels, in-ground storage, pipe lines, and embankments. the underlying potentially latent mechanisms of groundwater are classified into four groups, namely water pressure changes, physical changes, erosion, and affects of earthworks, in order to assist early identification of some of the types of change in ground properties which may be induced by site operations and may lead to damage. it is concluded that otherwise unforeseen damage is more likely to be averted by a greater degree of investigation during construction into the consequences of the construction sequences, method and plant used.   \n",
       "2                                                                                       acute hypoxia causes pulmonary vasoconstriction and coronary vasodilation. the divergent effects of hypoxia on pulmonary and coronary vascular smooth muscle cells suggest that the mechanisms involved in oxygen sensing and downstream effectors are different in these two types of cells. since production of reactive oxygen species (ros) is regulated by oxygen tension, ros have been hypothesized to be a signaling mechanism in hypoxia-induced pulmonary vasoconstriction and vascular remodeling. furthermore, an increased ros production is also implicated in arteriosclerosis. in this study, we determined and compared the effects of hypoxia on ros levels in human pulmonary arterial smooth muscle cells (pasmc) and coronary arterial smooth muscle cells (casmc). our results indicated that acute exposure to hypoxia (po2 = 25–30 mmhg for 5–10 min) significantly and rapidly decreased ros levels in both pasmc and casmc. however, chronic exposure to hypoxia (po2 = 30 mmhg for 48 h) markedly increased ros levels in pasmc, but decreased ros production in casmc. furthermore, chronic treatment with endothelin-1, a potent vasoconstrictor and mitogen, caused a significant increase in ros production in both pasmc and casmc. the inhibitory effect of acute hypoxia on ros production in pasmc was also accelerated in cells chronically treated with endothelin-1. while the decreased ros in pasmc and casmc after acute exposure to hypoxia may reflect the lower level of oxygen substrate available for ros production, the increased ros production in pasmc during chronic hypoxia may reflect a pathophysiological response unique to the pulmonary vasculature that contributes to the development of pulmonary vascular remodeling in patients with hypoxia-associated pulmonary hypertension.   \n",
       "3                                   despite rapid advances in the stem cell field, the ability to identify and track transplanted or migrating stem cells in vivo is limited. to overcome this limitation, we used magnetic resonance imaging (mri) to detect and follow transplanted stem cells over a period of 28 days in mice using an established myocardial infarction model. pluripotent mouse embryonic stem (mes) cells were expanded and induced to differentiate into beating cardiomyocytes in vitro. the cardiac-differentiated mes cells were then loaded with superparamagnetic fluorescent microspheres (1.63 μm in diameter) and transplanted into ischemic myocardium immediately following ligation and subsequent reperfusion of the left anterior descending coronary artery. to identify the transplanted stem cells in vivo, mri was performed using a varian inova 4.7 tesla scanner. our results show that (a) the cardiac-differentiated mes were effectively loaded with superparamagnetic microspheres in vitro, (b) the microsphere-loaded mes cells continued to beat in culture prior to transplantation, (c) the transplanted mes cells were readily detected in the heart in vivo using noninvasive mri techniques, (d) the transplanted stem cells were detected in ischemic myocardium for the entire 28-day duration of the study as confirmed by mri and post-mortem histological analyses, and (e) concurrent functional mri indicated typical loss of cardiac function, although significant amelioration of remodeling was noted after 28 days in hearts that received transplanted stem cells. these results demonstrate that it is feasible to simultaneously track transplanted stem cells and monitor cardiac function in vivo over an extended period using noninvasive mri techniques.\\n               disclosure of potential conflicts of interest is found at the end of this article.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       for the regenerative therapy of osteochondral defects – deep lesions of the articular cartilage in which the underlying bone tissue is already affected too – special implant materials and scaffolds are needed. in this study, two new approaches will be presented, leading to biphasic, but monolithic scaffold materials. both consist of a mineralised layer for filling of the bony part of the defect and a non-mineralised one for the chondral part. due to the preparation methods, both layers are fused together to give a unified whole without need of any artificial joining. the resulting materials, either based on collagen, hyaluronic acid and hydroxyapatite or calcium alginate gels and hydroxyapatite, seem to be suitable scaffolds for cultivating chondrocytes and osteoblasts – and therefore can act as matrices for tissue engineering of osteochondral grafts.   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ...   \n",
       "80276                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                the nymphal instars i and iii - v of sigara (tropocorixa) denseconscripta (breddin, 1897) are figured and described in detail, for the first time, with emphasis on morphometry and chaetotaxy of selected structures. the useful characters to identify the nymphal instars and the nymphs of the species of sigara are provided.   \n",
       "80277  the possible effects of a wide range of sociodemographic and environmental factors on the incidence and distribution of petechiae were investigated in 485 sudden infant death syndrome (sids) cases from the new zealand cot death study. the number (nil, few, many) of macroscopic petechial hemorrhages in the visceral pleura, capsule of thymus, and epicardium was recorded in 458 of 474 autopsied sids cases. other information was obtained from parental interview and obstetric records. univariate analysis showed highly significant relationships ( p ≤ 0.005) between the frequency of petechiae at one or more sites and socioeconomic status, parity, breast feeding, age at death, time of death, sleep position, and head covering at death and lesser but significant relationships ( p ≤ 0.05) with maori ethnicity, birth weight, gestation, pacifier use, and bed sharing. after multivariate analysis, significant associations remained between increased frequencies of thymic petechiae and parity (p = 0.0001), age at death (p = 0.0003), maori ethnicity (p = 0.0019), pacifier use (p = 0.0001), and head covering at death (p = 0.0032); between increased frequencies of epicardial petechiae and head covering at death (p = 0.008) and an estimated time of death between 00:00 and 05:59 h ( p = 0.056); and between increased frequencies of pleural petechiae and maternal smoking ( p = 0.058) and parity ( p = 0.022). there was a decreased frequency of pleural petechiae in infants placed prone for their final sleep ( p = 0.058). the distribution and frequency of petechiae are affected by environmental factors, including known risk factors for sids, but these factors occur inconsistently across the three sites. the findings imply differences in the pathogenesis at each site but do not provide consistent support for previous theories of causation of petechiae.   \n",
       "80278                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          after electroconvulsive therapy (ect), many patients experience a decrement in their mnestic capacity. we studied episodic memory in eight severely depressed patients treated with a course of right-unilateral ect. for this purpose, a testing instrument was constructed by the authors. it was made of paper cards that held four pieces of information, namely a word, a number, a figure, and the color of the card. one of the cards was presented to the patients and the respective information was asked for on the subsequent day. patients were tested every morning during the first two weeks of the ect course. about half of the responses were correct. patients did best in recalling the color; they did worst in recalling the number. seven of the patients showed verbal perseverations. this is in accordance with the literature on perseveration in patients with neurologic deficits, especially in proactive-inhibitory tasks. perseveration may be attributed to a deficit in selective attention, producing an arousal of irrelevant cues.   \n",
       "80279                     this article looks at the issue — largely neglected in the transition literature — of the relative weights of the privatized sector and the generic private sector (of de novo private firms) in the emerging private sector of post-communist economies in transition. the present writer posits that the relative weight of each in the aggregate share of a private sector (generally expanding over time as transition progresses) strongly influences economic performance, both during correctional recession and during recovery and expansion period. another, interrelated issue considered here is the interaction between the evolving institutional framework and the expansion of the generic private sector, that is the most dynamic one in the transition economy. it is true that the interaction between institutions and performance has been a staple of a very large number of books, articles, and papers.\\n               however, this article concentrates on one component of a private sector only, that is the generic private sector. but at the same time it looks beyond the ‘holy trinity’ of transition (stabilization, liberalization, and privatization) towards a wider institutional framework of political liberty, law and order. the foregoing wider framework, and the emerging general trust, matters as much — if not more — for the present writer as the standard transition program.\\n               it is the relative dynamics of both components of the private sector, affected by both standard transition programs and the above-mentioned wider institutional framework, that is of primary importance for the economic performance in post-communist transition. in the last part of the article i will try also to answer, tentatively, the question under which circumstances the wider institutional framework may emerge in the transition process.   \n",
       "80280                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             summarythere have been previous suggestions in the literature of a link between schizophrenia and retinitis pigmentosa (rp) or its associated syndromes. in this article, we describe two cases of schizophrenía and two cases of delusional disorder occurring in patients with rp. we explore possible reasons for an association between rp and schizophrenia including shared genetic predisposition, sensory deprivation, coarse brain disease and retinoid dysregulation. awareness of an association may help to direct future research into the aetiology of these disorders, especially in the areas of neurochemistry and medical genetics.   \n",
       "\n",
       "        cdindex  \n",
       "0      0.000000  \n",
       "1      0.000000  \n",
       "2     -0.002938  \n",
       "3     -0.004497  \n",
       "4     -0.004373  \n",
       "...         ...  \n",
       "80276 -0.100000  \n",
       "80277 -0.007576  \n",
       "80278 -0.040000  \n",
       "80279  0.100000  \n",
       "80280 -0.010811  \n",
       "\n",
       "[80281 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sup['abstract'] = df_sup['abstract'].apply(lambda x: re.sub(r'<.*?>', '', str(x)).replace(\"abstract\", \"\").strip().lower())\n",
    "df_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Access Network Selection in a 4G Environment</td>\n",
       "      <td>&lt;jats:p&gt;4G networks provide bandwidth of up to 1Gbps for a Mobile Node (MN) that is moving at pedestrian speed. On the other hand, it also supports mobile nodes that can move at a speed of 250 km/hr with bandwidths value of 100 Mbps. This sets the premise of a network that supports diverse needs. This goal will be harder to achieve if Network Selection Problems (NSP) are not addressed comprehensively. NSP refers to the selection of target access network selection from a collection of Candidate Networks (CNs) when MNs are moving from one access network into another. The most logical way of achieving this is to select the “best” network. This translates to identifying performance values of the CNs. The analysis in this chapter shows clearly that access network selection done based on limited criteria is detrimental in achieving optimum communication. Instead, this chapter suggests a framework that would be complementary to a 4G network.&lt;/jats:p&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Environmental Disclosures and Impression Management</td>\n",
       "      <td>&lt;jats:p&gt;A significant stream of social and environmental accounting research investigates the relationship between a corporation’s self-reported disclosures of its own social responsibility and environmental activities and third-party evaluations of that corporation’s actual social responsibility and environmental performance. Generally, researchers have utilized one of two theories to motivate and test this relationship. One theory—signaling or voluntary disclosure theory—argues that corporations with superior corporate social responsibility or environmental performance use disclosure to signal to interested parties a level of performance that poorer corporate performers cannot disclose. A second theory—legitimacy or impression management theory—argues that corporations use disclosures to manage impressions, often masking their actual social responsibility and environmental performance. In this chapter, the authors seek to comment on how DICTION has been and can be utilized to advance this stream of social and environmental accounting research. &lt;/jats:p&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0         Access Network Selection in a 4G Environment   \n",
       "1  Environmental Disclosures and Impression Management   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          abstract  \n",
       "0                                                                                                                    <jats:p>4G networks provide bandwidth of up to 1Gbps for a Mobile Node (MN) that is moving at pedestrian speed. On the other hand, it also supports mobile nodes that can move at a speed of 250 km/hr with bandwidths value of 100 Mbps. This sets the premise of a network that supports diverse needs. This goal will be harder to achieve if Network Selection Problems (NSP) are not addressed comprehensively. NSP refers to the selection of target access network selection from a collection of Candidate Networks (CNs) when MNs are moving from one access network into another. The most logical way of achieving this is to select the “best” network. This translates to identifying performance values of the CNs. The analysis in this chapter shows clearly that access network selection done based on limited criteria is detrimental in achieving optimum communication. Instead, this chapter suggests a framework that would be complementary to a 4G network.</jats:p>  \n",
       "1  <jats:p>A significant stream of social and environmental accounting research investigates the relationship between a corporation’s self-reported disclosures of its own social responsibility and environmental activities and third-party evaluations of that corporation’s actual social responsibility and environmental performance. Generally, researchers have utilized one of two theories to motivate and test this relationship. One theory—signaling or voluntary disclosure theory—argues that corporations with superior corporate social responsibility or environmental performance use disclosure to signal to interested parties a level of performance that poorer corporate performers cannot disclose. A second theory—legitimacy or impression management theory—argues that corporations use disclosures to manage impressions, often masking their actual social responsibility and environmental performance. In this chapter, the authors seek to comment on how DICTION has been and can be utilized to advance this stream of social and environmental accounting research. </jats:p>  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_un = pd.read_sql_query('SELECT title, abstract FROM works LEFT JOIN cdindex ON works.doi = cdindex.doi WHERE cdindex.doi IS NULL;', connection)\n",
    "df_un.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_un.to_csv('data/unsupervised_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate both models on exactly the same data we create a subset of our DataFrame that is the one tenth of our total data. \n",
    "\n",
    "Random state ensures reproducability when rerunning the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>abstract</th>\n",
       "      <th>cdindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9272</td>\n",
       "      <td>it has been successfully demonstrated that ceramic materials can be joined in the green\\nstate without a second phase by using low pressure injection molded parts. the investigation of the\\njoining interface revealed that a high quality interface can be achieved by carefully adjusting the\\ndifferent manufacturing steps. the use of monomodal particle size distribution in the used powder\\nct3000sg is inferior to a broader particle size distribution obtained by replacing 33% of the finer\\nalumina powder by coarser ct1200sg. in this way the dewaxing process is significantly improved\\nwhen the wall thickness of the part exceeds 3 mm. the investigation of the mechanical properties of\\nthe joined and sintered parts revealed, that the bending strength of the joined specimens achieved\\nabout 80 % of the unjoined, monolithic specimens.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71287</td>\n",
       "      <td>purpose\\n                in aspects, 10 brain regions are scored visually for presence of acute ischemic stroke damage. we evaluated automated aspects in comparison to expert readers.\\n              \\n                methods\\n                consecutive, baseline non-contrast ct-scans (5-mm slice thickness) from the prospective mr clean trial (n = 459, mr clean netherlands trial registry number: ntr1804) were evaluated. a two-observer consensus for aspects regions (normal/abnormal) was used as reference standard for training and testing (0.2/0.8 division). two other observers provided individual aspects-region scores. the automated aspects software was applied. a region score specificity of ≥ 90% was used to determine the software threshold for detection of an affected region based on relative density difference between affected and contralateral region. sensitivity, specificity, and receiver-operating characteristic curves were calculated. additionally, we assessed intraclass correlation coefficients (iccs) for automated aspects and observers in comparison to the reference standard in the test set.\\n              \\n                results\\n                in the training set (n = 104), with software thresholds for a specificity of ≥ 90%, we found a sensitivity of 33–49% and an area under the curve (auc) of 0.741–0.785 for detection of an affected aspects region. in the test set (n = 355), the results for the found software thresholds were 89–89% (specificity), 41–57% (sensitivity), and 0.750–0.795 (auc). comparison of automated aspects with the reference standard resulted in an icc of 0.526. comparison of observers with the reference standard resulted in an icc of 0.383–0.464.\\n              \\n                conclusion\\n                the performance of automated aspects is comparable to expert readers and could support readers in the detection of early ischemic changes.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18846</td>\n",
       "      <td>although sulfonylurea agents have been used in the clinical management of type ii diabetes (non-insulin-dependent diabetes mellitus, niddm) for over two decades, the mechanisms responsible for their hypoglycemie action remain controversial. we have quantitated glycemie control, endogenous insulin secretion in response to mixed meals, adipocyte insulin binding, insulin-mediated peripheral glucose disposal, and basal hepatic glucose output in 17 type ii diabetic subjects before and after 3 mo of therapy with the second-generation, sulfonylurea compound glyburide in an attempt to identify the factors responsible for the clinical response to the drug. in addition, 9 subjects were treated for an additional 15 mo to see if the response to the drug changed with time.\\n               the mean fasting serum glucose level fell from an initial value of 264 ± 17 mg/dl to 178 ± 16 mg/dl after 3 mo of drug therapy. endogenous insulin secretion increased in all subjects, but the increase was most marked in those subjects who continued to exhibit fasting hyperglycemie (fasting serum glucose &amp;amp;gt; 175 mg/dl) after 3 mo of therapy. adipocyte insulin binding was unchanged after 3 mo of therapy, while the maximal rate of peripheral glucose disposal was increased by 23%, indicating enhancement of peripheral insulin action at a postreceptor site(s). basal hepatic glucose output showed a significant correlation with the fasting serum glucose level both before and after therapy (r = 0.86, p &amp;amp;lt; 0.001) and fell from 141 ±12 mg/m2/min before therapy to 107 ± 11 mg/m2/min after 3 mo of therapy. a significant correlation was also found between the decrease in the fasting glucose level and both the reduction in basal hepatic glucose output (r = 0.81, p &amp;amp;lt; 0.001) and the enhancement of postreceptor function in peripheral tissues (r = 0.68, p &amp;amp;lt; 0.005). after 18 mo of therapy, those subjects exhibiting an initial good response to the drug demonstrated a slight decrease in endogenous insulin secretion compared with the levels seen at 3 mo, adipocyte insulin binding had increased to the normal range, postreceptor function was further enhanced, and basal hepatic glucose output remained unchanged from the levels observed after 3 mo of therapy.\\n               we conclude that (1) glyburide therapy increases endogenous insulin secretion, increases adipocyte insulin binding after 18, but not 3, mo of therapy, enhances peripheral insulin action by acting primarily at a post-receptor site, and reduces basal hepatic glucose output; (2) the increase in postreceptor function and the reduction of basal hepatic glucose output appear to be the crucial determinants of the clinical response to the sulfonylurea agent; and (3) the response pattern to sulfonylurea compounds in terms of these various parameters can vary as a function of the duration of treatment.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  \\\n",
       "0   9272   \n",
       "1  71287   \n",
       "2  18846   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               abstract  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 it has been successfully demonstrated that ceramic materials can be joined in the green\\nstate without a second phase by using low pressure injection molded parts. the investigation of the\\njoining interface revealed that a high quality interface can be achieved by carefully adjusting the\\ndifferent manufacturing steps. the use of monomodal particle size distribution in the used powder\\nct3000sg is inferior to a broader particle size distribution obtained by replacing 33% of the finer\\nalumina powder by coarser ct1200sg. in this way the dewaxing process is significantly improved\\nwhen the wall thickness of the part exceeds 3 mm. the investigation of the mechanical properties of\\nthe joined and sintered parts revealed, that the bending strength of the joined specimens achieved\\nabout 80 % of the unjoined, monolithic specimens.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    purpose\\n                in aspects, 10 brain regions are scored visually for presence of acute ischemic stroke damage. we evaluated automated aspects in comparison to expert readers.\\n              \\n                methods\\n                consecutive, baseline non-contrast ct-scans (5-mm slice thickness) from the prospective mr clean trial (n = 459, mr clean netherlands trial registry number: ntr1804) were evaluated. a two-observer consensus for aspects regions (normal/abnormal) was used as reference standard for training and testing (0.2/0.8 division). two other observers provided individual aspects-region scores. the automated aspects software was applied. a region score specificity of ≥ 90% was used to determine the software threshold for detection of an affected region based on relative density difference between affected and contralateral region. sensitivity, specificity, and receiver-operating characteristic curves were calculated. additionally, we assessed intraclass correlation coefficients (iccs) for automated aspects and observers in comparison to the reference standard in the test set.\\n              \\n                results\\n                in the training set (n = 104), with software thresholds for a specificity of ≥ 90%, we found a sensitivity of 33–49% and an area under the curve (auc) of 0.741–0.785 for detection of an affected aspects region. in the test set (n = 355), the results for the found software thresholds were 89–89% (specificity), 41–57% (sensitivity), and 0.750–0.795 (auc). comparison of automated aspects with the reference standard resulted in an icc of 0.526. comparison of observers with the reference standard resulted in an icc of 0.383–0.464.\\n              \\n                conclusion\\n                the performance of automated aspects is comparable to expert readers and could support readers in the detection of early ischemic changes.   \n",
       "2  although sulfonylurea agents have been used in the clinical management of type ii diabetes (non-insulin-dependent diabetes mellitus, niddm) for over two decades, the mechanisms responsible for their hypoglycemie action remain controversial. we have quantitated glycemie control, endogenous insulin secretion in response to mixed meals, adipocyte insulin binding, insulin-mediated peripheral glucose disposal, and basal hepatic glucose output in 17 type ii diabetic subjects before and after 3 mo of therapy with the second-generation, sulfonylurea compound glyburide in an attempt to identify the factors responsible for the clinical response to the drug. in addition, 9 subjects were treated for an additional 15 mo to see if the response to the drug changed with time.\\n               the mean fasting serum glucose level fell from an initial value of 264 ± 17 mg/dl to 178 ± 16 mg/dl after 3 mo of drug therapy. endogenous insulin secretion increased in all subjects, but the increase was most marked in those subjects who continued to exhibit fasting hyperglycemie (fasting serum glucose &amp;gt; 175 mg/dl) after 3 mo of therapy. adipocyte insulin binding was unchanged after 3 mo of therapy, while the maximal rate of peripheral glucose disposal was increased by 23%, indicating enhancement of peripheral insulin action at a postreceptor site(s). basal hepatic glucose output showed a significant correlation with the fasting serum glucose level both before and after therapy (r = 0.86, p &amp;lt; 0.001) and fell from 141 ±12 mg/m2/min before therapy to 107 ± 11 mg/m2/min after 3 mo of therapy. a significant correlation was also found between the decrease in the fasting glucose level and both the reduction in basal hepatic glucose output (r = 0.81, p &amp;lt; 0.001) and the enhancement of postreceptor function in peripheral tissues (r = 0.68, p &amp;lt; 0.005). after 18 mo of therapy, those subjects exhibiting an initial good response to the drug demonstrated a slight decrease in endogenous insulin secretion compared with the levels seen at 3 mo, adipocyte insulin binding had increased to the normal range, postreceptor function was further enhanced, and basal hepatic glucose output remained unchanged from the levels observed after 3 mo of therapy.\\n               we conclude that (1) glyburide therapy increases endogenous insulin secretion, increases adipocyte insulin binding after 18, but not 3, mo of therapy, enhances peripheral insulin action by acting primarily at a post-receptor site, and reduces basal hepatic glucose output; (2) the increase in postreceptor function and the reduction of basal hepatic glucose output appear to be the crucial determinants of the clinical response to the sulfonylurea agent; and (3) the response pattern to sulfonylurea compounds in terms of these various parameters can vary as a function of the duration of treatment.   \n",
       "\n",
       "   cdindex  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(df_sup.sample(frac=0.1, random_state=42))\n",
    "test_df.reset_index(inplace=True)\n",
    "test_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our training and test datasets as a scikit-learn Bunch object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Bunch(\n",
    "    data=df_sup['abstract'].values,\n",
    "    target=df_sup['cdindex'].values,\n",
    "    target_names=['cdindex'],\n",
    "    DESCR='Scikit-learn dataset from dataframe'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Bunch(\n",
    "    data=test_df['abstract'].values,\n",
    "    target=test_df['cdindex'].values,\n",
    "    target_names=['cdindex'],\n",
    "    DESCR='Scikit-learn dataset from dataframe'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shuffle our training data to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data, dataset.target = shuffle(dataset.data, dataset.target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the non Neural Network approach I decided to use a booster. \n",
    "\n",
    "Specifically, an XGBooster. We create a Pipeline with a CountVectorizer, a tf-idf transformer and the XGBooster as the final layer to make the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', XGBRegressor()),\n",
    "                    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                              colsample_bylevel=None, colsample_bynode=None,\n",
       "                              colsample_bytree=None, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              feature_types=None, gamma=None, gpu_id=None,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=None, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=100,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              predictor=None, random_state=None, ...))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(dataset.data, dataset.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate our model we use the following metrics:\n",
    "\n",
    "1. Mean-Squared-Error: \n",
    "\n",
    "    *Average of the squared differences between the predicted values and the actual values. (Penalizes larger errors severely more)*\n",
    "\n",
    "    $MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$ , \n",
    "\n",
    "\n",
    "2. Mean Absolute Error: \n",
    "\n",
    "    *Average of the absolute differences between the predicted values and the actual values.*\n",
    "\n",
    "    $MAE = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|$\n",
    "\n",
    "3. Root Mean Squared Error: \n",
    "\n",
    "    *Square root of the MSE. It provides a more interpretable measure of the magnitude of the error, as it's expressed in the same units as the target variable.*\n",
    "\n",
    "    $RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}$\n",
    "\n",
    "4. R Squared: \n",
    "\n",
    "    *Measures the proportion of the variance in the target variable that is explained by the model.*\n",
    "\n",
    "    $R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$\n",
    "\n",
    "5. Adjusted R Squared: \n",
    "\n",
    "    *Takes into account the number of predictors in the model. It provides a more robust measure of the goodness of fit, as it adjusts for the number of predictors.*\n",
    "\n",
    "    $Adj. R^2 = 1 - \\frac{(1-R^2)(n-1)}{n-p-1}$\n",
    "\n",
    "#### Where:\n",
    "\n",
    "*$n$: Number of observations*\n",
    "\n",
    "*$y_i$: actual value of endogenous variable* \n",
    "\n",
    "*$\\hat{y}_i$: predicted value for the endogenous variable*\n",
    "\n",
    "*$SS_{res} = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$*\n",
    "\n",
    "*$SS_{tot} = \\sum_{i=1}^{n}(y_i - \\bar{y})^2$*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.26523003279745855 \n",
      "MSE: 0.11778570133007003\n",
      "R-squared: 0.3435726543048321\n",
      "Root Mean Squared Error 0.3431992152235637\n",
      "Adjusted R-squared: 0.34349086669634776\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(test_dataset.data)\n",
    "r2 = r2_score(y_true=test_dataset.target, y_pred=predicted)\n",
    "mae = mean_absolute_error(y_true=test_dataset.target, y_pred=predicted)\n",
    "mse = mean_squared_error(y_true=test_dataset.target, y_pred=predicted)\n",
    "adjusted_r2 = 1 - (1 - r2) * (len(test_df) - 1) / (len(test_df) - 1 - 1)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"MAE: {mae} \\nMSE: {mse}\\nR-squared: {r2}\\nRoot Mean Squared Error {rmse}\\nAdjusted R-squared: {adjusted_r2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the complexity of the problem and the simplicity of our model, we get some alright results. However, we want to take it a step further and try to optimize our current model and particularly the booster.\n",
    "\n",
    "Hence we will perform a grid search for the :\n",
    "1. Learning Rate: Step size of the gradient descent algorithm\n",
    "\n",
    "2. N Estimators: Number of trees in the model\n",
    "\n",
    "3. Max Depth: Maximum depth of each tree\n",
    "\n",
    "4. Reg Alpha: L1 (Lasso) regularization to prevent overfitting\n",
    "\n",
    "5. Reg Lambda: L2 (Ridge) regularization to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'clf__learning_rate': [0.01, 0.1],\n",
    "    'clf__n_estimators': [100, 500, 1000],\n",
    "    'clf__max_depth': [3, 5, 7],\n",
    "    'clf__reg_alpha': [0.1, 0.2],\n",
    "    'clf__reg_lambda': [0.1, 0.2]\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(dataset.data, dataset.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the best values for these hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__learning_rate': 0.1,\n",
       " 'clf__max_depth': 3,\n",
       " 'clf__n_estimators': 1000,\n",
       " 'clf__reg_alpha': 0.2,\n",
       " 'clf__reg_lambda': 0.2}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new Pipeline with the hyperparameters set to these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_tuned = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', XGBRegressor(learning_rate=0.1, max_depth=3, n_estimators=1000, reg_alpha=0.2, reg_lambda=0.2)),\n",
    "                    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                              colsample_bylevel=None, colsample_bynode=None,\n",
       "                              colsample_bytree=None, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              feature_types=None, gamma=None, gpu_id=None,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.1,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=3, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=1000,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              predictor=None, random_state=None, ...))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_tuned.fit(dataset.data, dataset.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.2725061265042144 \n",
      "MSE: 0.12209454814552814\n",
      "R-squared: 0.31955917180111026\n",
      "Root Mean Squared Error 0.34942030299558746\n",
      "Adjusted R-squared: 0.3194743922311877\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf_tuned.predict(test_dataset.data)\n",
    "r2 = r2_score(y_true=test_dataset.target, y_pred=predicted)\n",
    "mae = mean_absolute_error(y_true=test_dataset.target, y_pred=predicted)\n",
    "mse = mean_squared_error(y_true=test_dataset.target, y_pred=predicted)\n",
    "adjusted_r2 = 1 - (1 - r2) * (len(test_df) - 1) / (len(test_df) - 1 - 1)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"MAE: {mae} \\nMSE: {mse}\\nR-squared: {r2}\\nRoot Mean Squared Error {rmse}\\nAdjusted R-squared: {adjusted_r2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network appoach with BERT (Bidirectional Encoder Representation from Transformers).\n",
    "\n",
    "*The [paper](https://arxiv.org/abs/1810.04805) that inspired this approach*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <b>Transformer Architecture</b>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "    <img src=\"imgs/transformer_arch.png\" alt=\"Image Description\" width=\"350\" height=\"500\">\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT makes use of the Transformer architecture, an attention mechanism that learns contextual relations between words (or sub-words) in a text. As opposed to directional models, which read text sequentially, the Transformer encoder reads the entire sequence of words at once, thus allowing the model to learn the context of a word based on its surroundings. BERT makes use of two techniques:\n",
    "1. Masked Language Model (MLM)\n",
    "\n",
    "2. Next Sentence Prediction (NSP)\n",
    "\n",
    "However we will be implementing MLM BERT since we are interested in the contextual relationships between words.\n",
    "MLM training comprises of replacing 15% of the words in each sentence with a < MASK > token and trying to predict said word based on the context of a sentence. As a result BERT trains on the notion of context. Something to underline is that the BERT loss function considers only the prediction of the masked values and ignores the prediction of non-masked values in order to better enhance BERT’s context awareness.\n",
    "    \n",
    "    Input: The < MASK1 > brown fox < MASK2 > over the lazy frog.\n",
    "    \n",
    "    Output: < MASK1 > = quick, < MASK2 > = jumped\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"imgs/bert_input.png\">\n",
    "</p>\n",
    "\n",
    "\n",
    "Furthermore, since we have some unlabeled data, I decided to split the training process. Firtsly we will fine-tune BERT's weights to the context of our problem by feeding him the unlabeled data (label being the cdindex). This is a common approach that ensures that before we tackle the main problem BERT already has a sense of what's the context of the input, in hopes to make better predictions and speed up the training process. \n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"imgs/pre-fine.png\">\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What prompted me to use BERT for MLM, was to explore whether a context-based-only approach would work for our problem since the authors of the paper frequently underline the importance of context.\n",
    "\n",
    "In order to further leverage BERT's way of training, I decided to concatenate the titles of the papers to the abstracts since most of the time the titles are indicative of the paper's context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Access Network Selection in a 4G Environment</td>\n",
       "      <td>&lt;jats:p&gt;4G networks provide bandwidth of up to 1Gbps for a Mobile Node (MN) that is moving at pedestrian speed. On the other hand, it also supports mobile nodes that can move at a speed of 250 km/hr with bandwidths value of 100 Mbps. This sets the premise of a network that supports diverse needs. This goal will be harder to achieve if Network Selection Problems (NSP) are not addressed comprehensively. NSP refers to the selection of target access network selection from a collection of Candidate Networks (CNs) when MNs are moving from one access network into another. The most logical way of achieving this is to select the “best” network. This translates to identifying performance values of the CNs. The analysis in this chapter shows clearly that access network selection done based on limited criteria is detrimental in achieving optimum communication. Instead, this chapter suggests a framework that would be complementary to a 4G network.&lt;/jats:p&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title  \\\n",
       "0  Access Network Selection in a 4G Environment   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        abstract  \n",
       "0  <jats:p>4G networks provide bandwidth of up to 1Gbps for a Mobile Node (MN) that is moving at pedestrian speed. On the other hand, it also supports mobile nodes that can move at a speed of 250 km/hr with bandwidths value of 100 Mbps. This sets the premise of a network that supports diverse needs. This goal will be harder to achieve if Network Selection Problems (NSP) are not addressed comprehensively. NSP refers to the selection of target access network selection from a collection of Candidate Networks (CNs) when MNs are moving from one access network into another. The most logical way of achieving this is to select the “best” network. This translates to identifying performance values of the CNs. The analysis in this chapter shows clearly that access network selection done based on limited criteria is detrimental in achieving optimum communication. Instead, this chapter suggests a framework that would be complementary to a 4G network.</jats:p>  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_un = pd.read_csv('data/unsupervised_data.csv')\n",
    "df_un.iloc[:1, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Access Network Selection in a 4G Environment. <jats:p>4G networks provide bandwidth of up to 1Gbps for a Mobile Node (MN) that is moving at pedestrian speed. On the other hand, it also supports mobile nodes that can move at a speed of 250 km/hr with bandwidths value of 100 Mbps. This sets the premise of a network that supports diverse needs. This goal will be harder to achieve if Network Selection Problems (NSP) are not addressed comprehensively. NSP refers to the selection of target access network selection from a collection of Candidate Networks (CNs) when MNs are moving from one access network into another. The most logical way of achieving this is to select the “best” network. This translates to identifying performance values of the CNs. The analysis in this chapter shows clearly that access network selection done based on limited criteria is detrimental in achieving optimum communication. Instead, this chapter suggests a framework that would be complementary to a 4G network.</jats:p>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_un['concatenated'] = df_un['title'] + '. ' + df_un['abstract']\n",
    "df_un.at[0, 'concatenated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Access Network Selection in a 4G Environment. 4G networks provide bandwidth of up to 1Gbps for a Mobile Node (MN) that is moving at pedestrian speed. On the other hand, it also supports mobile nodes that can move at a speed of 250 km/hr with bandwidths value of 100 Mbps. This sets the premise of a network that supports diverse needs. This goal will be harder to achieve if Network Selection Problems (NSP) are not addressed comprehensively. NSP refers to the selection of target access network selection from a collection of Candidate Networks (CNs) when MNs are moving from one access network into another. The most logical way of achieving this is to select the “best” network. This translates to identifying performance values of the CNs. The analysis in this chapter shows clearly that access network selection done based on limited criteria is detrimental in achieving optimum communication. Instead, this chapter suggests a framework that would be complementary to a 4G network.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_un['concatenated'] = df_un['concatenated'].apply(lambda x: re.sub('<.*?>', '', str(x)).strip())\n",
    "df_un.at[0, 'concatenated']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import a BERT tokenizer and an instance of a pre-trained MLM BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards we make a list of the *concatenated* column and pass it to the tokenizer in order to create some < MASK > tokens within our training data.\n",
    "\n",
    "(We pad any sentences that are less than 512 and truncate these that are greater than our threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Access Network Selection in a 4G Environment. 4G networks provide bandwidth of up to 1Gbps for a Mobile Node (MN) that is moving at pedestrian speed. On the other hand, it also supports mobile nodes that can move at a speed of 250 km/hr with bandwidths value of 100 Mbps. This sets the premise of a network that supports diverse needs. This goal will be harder to achieve if Network Selection Problems (NSP) are not addressed comprehensively. NSP refers to the selection of target access network selection from a collection of Candidate Networks (CNs) when MNs are moving from one access network into another. The most logical way of achieving this is to select the “best” network. This translates to identifying performance values of the CNs. The analysis in this chapter shows clearly that access network selection done based on limited criteria is detrimental in achieving optimum communication. Instead, this chapter suggests a framework that would be complementary to a 4G network.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = df_un['concatenated'].tolist()\n",
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  3229,  2897,  ...,     0,     0,     0],\n",
       "        [  101,  4483, 19380,  ...,     0,     0,     0],\n",
       "        [  101,  4106,  1997,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  4613, 22334,  ...,     0,     0,     0],\n",
       "        [  101,  2203, 14573,  ..., 15136,  2509,   102],\n",
       "        [  101,  4254,  1997,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(data_list, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
    "inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we pass the inputs as the labels since we are only training to bring context awareness to our model, where the input is the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  3229,  2897,  ...,     0,     0,     0],\n",
       "        [  101,  4483, 19380,  ...,     0,     0,     0],\n",
       "        [  101,  4106,  1997,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  4613, 22334,  ...,     0,     0,     0],\n",
       "        [  101,  2203, 14573,  ..., 15136,  2509,   102],\n",
       "        [  101,  4254,  1997,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[  101,  3229,  2897,  ...,     0,     0,     0],\n",
       "        [  101,  4483, 19380,  ...,     0,     0,     0],\n",
       "        [  101,  4106,  1997,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  4613, 22334,  ...,     0,     0,     0],\n",
       "        [  101,  2203, 14573,  ..., 15136,  2509,   102],\n",
       "        [  101,  4254,  1997,  ...,     0,     0,     0]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create our < MASK > tokens with 15 % probability. However we do not want to take the CLS (101) and SEP (102) tokens into consideration, hence the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False,  True,  True,  ..., False, False, False],\n",
       "        [False, False,  True,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "mask_arr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we retrieve the index possitions of the True values (the words that will be masked) and proceed to apply the < MASK > token by inserting the numeric value of the token, which is 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are working with our own custom dataset, we have to create a class that inherits form *torch.utils.data.Dataset* in order to train our model. This class must define three methods: \n",
    "1. __ init__()\n",
    "2. __ getitem__()\n",
    "3. __ len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupervisedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instanciate our dataset and split it into into training and validation subsets using an 80 - 20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UnsupervisedDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexf\\AppData\\Local\\Temp\\ipykernel_128784\\3990795676.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9149, 2288)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ratio = 0.2\n",
    "train_dataset, val_dataset, _, _ = train_test_split(dataset, range(len(dataset)), test_size=val_ratio, random_state=42)\n",
    "\n",
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also instanciate two *torch.utils.data.DataLoader* objects, one for each subset of our data, The *torch.utils.data.Dataset* retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval. DataLoader is an iterable that abstracts this complexity for us in an easy API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have some device-agnostic code and put the model on that device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciate our optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexf\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optim = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training procedure. \n",
    "\n",
    "Since our problem is pretty complex it is very easy for our model to overfit to the training data, therefore we must take some measures to counter that. We introduce two variables *counter* and *patience*. *Counter* keeps track of the number of epochs that passed since our model last made a new validation loss minimum, while *patience* is a threshold that reflects the maximum number of epochs that we allow our model to keep training while performing worse in its validation subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49ed655944846bb8ab5cdb0cf79949c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Batch: 1000 Training Loss: 0.2849548095390201\n",
      "Average Training Loss:  0.275\n",
      "Average Validation Loss: 0.193\n",
      "Epoch 2\n",
      "Batch: 1000 Training Loss: 0.17069116331636905\n",
      "Average Training Loss:  0.171\n",
      "Average Validation Loss: 0.190\n",
      "Epoch 3\n",
      "Batch: 1000 Training Loss: 0.13633696671947837\n",
      "Average Training Loss:  0.137\n",
      "Average Validation Loss: 0.195\n",
      "Epoch 4\n",
      "Batch: 1000 Training Loss: 0.10752261646091937\n",
      "Average Training Loss:  0.108\n",
      "Average Validation Loss: 0.202\n",
      "Epoch 5\n",
      "Batch: 1000 Training Loss: 0.08262827629968524\n",
      "Average Training Loss:  0.083\n",
      "Average Validation Loss: 0.212\n",
      "Epoch 6\n",
      "Batch: 1000 Training Loss: 0.06235021597146988\n",
      "Average Training Loss:  0.063\n",
      "Average Validation Loss: 0.222\n",
      "Early stopping at epoch 6 due to overfitting.\n",
      "Best model occured on epoch: 2\n"
     ]
    }
   ],
   "source": [
    "epochs = 7\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "best_loss = 1000000\n",
    "counter = 0\n",
    "patience = 4\n",
    "for epoch in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    # Toggle model on training mode\n",
    "    model.train()\n",
    "    current_training_loss = 0\n",
    "    # Iterate DataLoader\n",
    "    for i, batch in enumerate(train_dl):\n",
    "        # Clear optimizer\n",
    "        optim.zero_grad()\n",
    "        # Extract features, attention mask and labels\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # Foward Feed\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,labels=labels)\n",
    "        # Calculate Loss\n",
    "        loss = outputs.loss\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        optim.step()\n",
    "        current_training_loss += loss.item()\n",
    "        # Every 1000 batches\n",
    "        if i % 1000 == 999:\n",
    "          last_loss = current_training_loss / 1000 # loss per batch\n",
    "          print(f'Batch: {i + 1} Training Loss: {last_loss}')\n",
    "    avg_loss = current_training_loss / (i + 1)\n",
    "    training_loss.append(avg_loss)\n",
    "\n",
    "    # Toggle model on evaluation mode\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    # Iterate DataLoader\n",
    "    for i, batch in enumerate(val_dl):\n",
    "        # Extract features, attention mask and labels\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # Foward Feed\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,labels=labels)\n",
    "        # Calculate Loss\n",
    "        loss = outputs.loss\n",
    "        val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / (i + 1)\n",
    "    validation_loss.append(avg_val_loss)\n",
    "    print(f'Average Training Loss: {avg_loss : .3f}')\n",
    "    print(f'Average Validation Loss:{avg_val_loss: .3f}')\n",
    "    # Based on model's improvement, store weights or track overfitting\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_epoch = epoch + 1\n",
    "        best_loss = avg_val_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), f'model_{epoch + 1}.pt')\n",
    "    else:\n",
    "        counter += 1\n",
    "    # Assess threshold breach\n",
    "    if counter >= patience:\n",
    "        print(f'Early stopping at epoch {epoch + 1} due to overfitting.')\n",
    "        print(f'Best model occured on epoch: {best_epoch}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.275035149202897,\n",
       "  0.17073363604974914,\n",
       "  0.13669991432982204,\n",
       "  0.10800728588071945,\n",
       "  0.08317175218705218,\n",
       "  0.06327083100519189],\n",
       " [0.1931126386291914,\n",
       "  0.1903761250155789,\n",
       "  0.1950919846711042,\n",
       "  0.2020932961437669,\n",
       "  0.21203507412667874,\n",
       "  0.22225573440114935])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss, validation_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will tackle predicting the value of the cdindex.\n",
    "\n",
    "We create our model's class that inherits from *nn.Module* and that comprises of our context fine-tuned model and three fully connected layers stacked on top. The first two have a ReLU activation function in an attempt to catch more complex relationships in the data whilst the last has a linear activation in order to predict the value of the index.  In addition to that we incorporate some *Dropout* layers to combat overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "class IndexPredictor(nn.Module):\n",
    "    def __init__(self, bert_model):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.fc1 = nn.Linear(in_features=30522, out_features=768)\n",
    "        self.fc2 = nn.Linear(in_features=768, out_features=512)\n",
    "        self.fc3 = nn.Linear(in_features=512, out_features=1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs[0] # (batch_size, sequence_length, hidden_size)\n",
    "        pooled_output = last_hidden_state[:, 0] # (batch_size, hidden_size)\n",
    "        index = self.dropout1(F.relu(self.fc1(pooled_output)))\n",
    "        index = self.dropout2(F.relu(self.fc2(index)))\n",
    "        return self.fc3(index)\n",
    "\n",
    "# Load fine-tuned BERT model\n",
    "bert_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "bert_model.load_state_dict(torch.load('models/model_2.pt', map_location=device))\n",
    "# Create the new IndexPredictor model\n",
    "model2 = IndexPredictor(bert_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instanciate a DataFrame object containing all the abstracts that have a *cdindex* value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>cdindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The photolysis of dilute solutions of octacyclosulphur or hexacyclosulphur in n-hexane with 253.6 nm UV radiation produces S and possibly S2. The ‘ring-opening’ yields of these sulphur molecules range from 0.2 to 0.7. When the hydrogen end-capped polyyne C10H2 is irradiated in n-hexane, it transforms into unidentified products with a quantum yield of 3×10−5. When octacyclosulphur is added to the solution, the yield rises to 7×10−3. The putative sulphur-bearing product(s) could not be identified. It is suggested that sulphur-bearing molecules might be formed in astronomical settings by reactions of carbon molecules having triple or double C—C bonds with photolytically produced S and/or S2.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Examples are given of unforeseen damage or difficulties arising during or after construction of buildings, wharves, foundations, tunnels, in-ground storage, pipe lines, and embankments. The underlying potentially latent mechanisms of groundwater are classified into four groups, namely water pressure changes, physical changes, erosion, and affects of earthworks, in order to assist early identification of some of the types of change in ground properties which may be induced by site operations and may lead to damage. It is concluded that otherwise unforeseen damage is more likely to be averted by a greater degree of investigation during construction into the consequences of the construction sequences, method and plant used.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acute hypoxia causes pulmonary vasoconstriction and coronary vasodilation. The divergent effects of hypoxia on pulmonary and coronary vascular smooth muscle cells suggest that the mechanisms involved in oxygen sensing and downstream effectors are different in these two types of cells. Since production of reactive oxygen species (ROS) is regulated by oxygen tension, ROS have been hypothesized to be a signaling mechanism in hypoxia-induced pulmonary vasoconstriction and vascular remodeling. Furthermore, an increased ROS production is also implicated in arteriosclerosis. In this study, we determined and compared the effects of hypoxia on ROS levels in human pulmonary arterial smooth muscle cells (PASMC) and coronary arterial smooth muscle cells (CASMC). Our results indicated that acute exposure to hypoxia (Po2 = 25–30 mmHg for 5–10 min) significantly and rapidly decreased ROS levels in both PASMC and CASMC. However, chronic exposure to hypoxia (Po2 = 30 mmHg for 48 h) markedly increased ROS levels in PASMC, but decreased ROS production in CASMC. Furthermore, chronic treatment with endothelin-1, a potent vasoconstrictor and mitogen, caused a significant increase in ROS production in both PASMC and CASMC. The inhibitory effect of acute hypoxia on ROS production in PASMC was also accelerated in cells chronically treated with endothelin-1. While the decreased ROS in PASMC and CASMC after acute exposure to hypoxia may reflect the lower level of oxygen substrate available for ROS production, the increased ROS production in PASMC during chronic hypoxia may reflect a pathophysiological response unique to the pulmonary vasculature that contributes to the development of pulmonary vascular remodeling in patients with hypoxia-associated pulmonary hypertension.</td>\n",
       "      <td>-0.002938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Despite rapid advances in the stem cell field, the ability to identify and track transplanted or migrating stem cells in vivo is limited. To overcome this limitation, we used magnetic resonance imaging (MRI) to detect and follow transplanted stem cells over a period of 28 days in mice using an established myocardial infarction model. Pluripotent mouse embryonic stem (mES) cells were expanded and induced to differentiate into beating cardiomyocytes in vitro. The cardiac-differentiated mES cells were then loaded with superparamagnetic fluorescent microspheres (1.63 μm in diameter) and transplanted into ischemic myocardium immediately following ligation and subsequent reperfusion of the left anterior descending coronary artery. To identify the transplanted stem cells in vivo, MRI was performed using a Varian Inova 4.7 Tesla scanner. Our results show that (a) the cardiac-differentiated mES were effectively loaded with superparamagnetic microspheres in vitro, (b) the microsphere-loaded mES cells continued to beat in culture prior to transplantation, (c) the transplanted mES cells were readily detected in the heart in vivo using noninvasive MRI techniques, (d) the transplanted stem cells were detected in ischemic myocardium for the entire 28-day duration of the study as confirmed by MRI and post-mortem histological analyses, and (e) concurrent functional MRI indicated typical loss of cardiac function, although significant amelioration of remodeling was noted after 28 days in hearts that received transplanted stem cells. These results demonstrate that it is feasible to simultaneously track transplanted stem cells and monitor cardiac function in vivo over an extended period using noninvasive MRI techniques.\\n               Disclosure of potential conflicts of interest is found at the end of this article.</td>\n",
       "      <td>-0.004497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For the regenerative therapy of osteochondral defects – deep lesions of the articular cartilage in which the underlying bone tissue is already affected too – special implant materials and scaffolds are needed. In this study, two new approaches will be presented, leading to biphasic, but monolithic scaffold materials. Both consist of a mineralised layer for filling of the bony part of the defect and a non-mineralised one for the chondral part. Due to the preparation methods, both layers are fused together to give a unified whole without need of any artificial joining. The resulting materials, either based on collagen, hyaluronic acid and hydroxyapatite or calcium alginate gels and hydroxyapatite, seem to be suitable scaffolds for cultivating chondrocytes and osteoblasts – and therefore can act as matrices for tissue engineering of osteochondral grafts.</td>\n",
       "      <td>-0.004373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              abstract  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            The photolysis of dilute solutions of octacyclosulphur or hexacyclosulphur in n-hexane with 253.6 nm UV radiation produces S and possibly S2. The ‘ring-opening’ yields of these sulphur molecules range from 0.2 to 0.7. When the hydrogen end-capped polyyne C10H2 is irradiated in n-hexane, it transforms into unidentified products with a quantum yield of 3×10−5. When octacyclosulphur is added to the solution, the yield rises to 7×10−3. The putative sulphur-bearing product(s) could not be identified. It is suggested that sulphur-bearing molecules might be formed in astronomical settings by reactions of carbon molecules having triple or double C—C bonds with photolytically produced S and/or S2.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Examples are given of unforeseen damage or difficulties arising during or after construction of buildings, wharves, foundations, tunnels, in-ground storage, pipe lines, and embankments. The underlying potentially latent mechanisms of groundwater are classified into four groups, namely water pressure changes, physical changes, erosion, and affects of earthworks, in order to assist early identification of some of the types of change in ground properties which may be induced by site operations and may lead to damage. It is concluded that otherwise unforeseen damage is more likely to be averted by a greater degree of investigation during construction into the consequences of the construction sequences, method and plant used.   \n",
       "2                                                      Acute hypoxia causes pulmonary vasoconstriction and coronary vasodilation. The divergent effects of hypoxia on pulmonary and coronary vascular smooth muscle cells suggest that the mechanisms involved in oxygen sensing and downstream effectors are different in these two types of cells. Since production of reactive oxygen species (ROS) is regulated by oxygen tension, ROS have been hypothesized to be a signaling mechanism in hypoxia-induced pulmonary vasoconstriction and vascular remodeling. Furthermore, an increased ROS production is also implicated in arteriosclerosis. In this study, we determined and compared the effects of hypoxia on ROS levels in human pulmonary arterial smooth muscle cells (PASMC) and coronary arterial smooth muscle cells (CASMC). Our results indicated that acute exposure to hypoxia (Po2 = 25–30 mmHg for 5–10 min) significantly and rapidly decreased ROS levels in both PASMC and CASMC. However, chronic exposure to hypoxia (Po2 = 30 mmHg for 48 h) markedly increased ROS levels in PASMC, but decreased ROS production in CASMC. Furthermore, chronic treatment with endothelin-1, a potent vasoconstrictor and mitogen, caused a significant increase in ROS production in both PASMC and CASMC. The inhibitory effect of acute hypoxia on ROS production in PASMC was also accelerated in cells chronically treated with endothelin-1. While the decreased ROS in PASMC and CASMC after acute exposure to hypoxia may reflect the lower level of oxygen substrate available for ROS production, the increased ROS production in PASMC during chronic hypoxia may reflect a pathophysiological response unique to the pulmonary vasculature that contributes to the development of pulmonary vascular remodeling in patients with hypoxia-associated pulmonary hypertension.   \n",
       "3  Despite rapid advances in the stem cell field, the ability to identify and track transplanted or migrating stem cells in vivo is limited. To overcome this limitation, we used magnetic resonance imaging (MRI) to detect and follow transplanted stem cells over a period of 28 days in mice using an established myocardial infarction model. Pluripotent mouse embryonic stem (mES) cells were expanded and induced to differentiate into beating cardiomyocytes in vitro. The cardiac-differentiated mES cells were then loaded with superparamagnetic fluorescent microspheres (1.63 μm in diameter) and transplanted into ischemic myocardium immediately following ligation and subsequent reperfusion of the left anterior descending coronary artery. To identify the transplanted stem cells in vivo, MRI was performed using a Varian Inova 4.7 Tesla scanner. Our results show that (a) the cardiac-differentiated mES were effectively loaded with superparamagnetic microspheres in vitro, (b) the microsphere-loaded mES cells continued to beat in culture prior to transplantation, (c) the transplanted mES cells were readily detected in the heart in vivo using noninvasive MRI techniques, (d) the transplanted stem cells were detected in ischemic myocardium for the entire 28-day duration of the study as confirmed by MRI and post-mortem histological analyses, and (e) concurrent functional MRI indicated typical loss of cardiac function, although significant amelioration of remodeling was noted after 28 days in hearts that received transplanted stem cells. These results demonstrate that it is feasible to simultaneously track transplanted stem cells and monitor cardiac function in vivo over an extended period using noninvasive MRI techniques.\\n               Disclosure of potential conflicts of interest is found at the end of this article.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      For the regenerative therapy of osteochondral defects – deep lesions of the articular cartilage in which the underlying bone tissue is already affected too – special implant materials and scaffolds are needed. In this study, two new approaches will be presented, leading to biphasic, but monolithic scaffold materials. Both consist of a mineralised layer for filling of the bony part of the defect and a non-mineralised one for the chondral part. Due to the preparation methods, both layers are fused together to give a unified whole without need of any artificial joining. The resulting materials, either based on collagen, hyaluronic acid and hydroxyapatite or calcium alginate gels and hydroxyapatite, seem to be suitable scaffolds for cultivating chondrocytes and osteoblasts – and therefore can act as matrices for tissue engineering of osteochondral grafts.   \n",
       "\n",
       "    cdindex  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2 -0.002938  \n",
       "3 -0.004497  \n",
       "4 -0.004373  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sup = pd.read_csv('data/data.csv')\n",
    "df_sup.drop(columns='Unnamed: 0', inplace=True)\n",
    "df_sup.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the data preprocessing we follow the same procedure as before.\n",
    "\n",
    "We convert our data to a list and pass it to the BERT tokenizer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer1 = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sup['abstract'] = df_sup['abstract'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The photolysis of dilute solutions of octacyclosulphur or hexacyclosulphur in n-hexane with 253.6\\xa0nm UV radiation produces S and possibly S2. The ‘ring-opening’ yields of these sulphur molecules range from 0.2 to 0.7. When the hydrogen end-capped polyyne C10H2 is irradiated in n-hexane, it transforms into unidentified products with a quantum yield of 3×10−5. When octacyclosulphur is added to the solution, the yield rises to 7×10−3. The putative sulphur-bearing product(s) could not be identified. It is suggested that sulphur-bearing molecules might be formed in astronomical settings by reactions of carbon molecules having triple or double C—C bonds with photolytically produced S and/or S2.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = df_sup['abstract'].tolist()\n",
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1996,  6302,  ...,     0,     0,     0],\n",
       "        [  101,  4973,  2024,  ...,     0,     0,     0],\n",
       "        [  101, 11325,  1044,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2044, 16175,  ...,     0,     0,     0],\n",
       "        [  101,  2023,  3720,  ...,     0,     0,     0],\n",
       "        [  101, 12654, 12399,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer1(data_list, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
    "inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the mask array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False,  True,  ..., False, False, False],\n",
       "        [False,  True,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "mask_arr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace the True values with the < MASK > token (103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new class that inherits from *torch.utils.data.Dataset*. However we modify the __ getitem__() method to also retrive the value of the cdindex from every abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CdindexDataset1(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, Y):\n",
    "        self.encodings = encodings\n",
    "        self.Y = torch.tensor(Y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}, self.Y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CdindexDataset1(inputs, df_sup['cdindex'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into training and validation subsets, using an 80 - 20 ratio respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexf\\AppData\\Local\\Temp\\ipykernel_128784\\3350416938.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}, self.Y[idx]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64224, 16057)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ratio = 0.2\n",
    "train_dataset, val_dataset, _, _ = train_test_split(dataset, range(len(dataset)), test_size=val_ratio, random_state=42)\n",
    "\n",
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instanciate a DataLoader object for each data subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write some device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndexPredictor(\n",
       "  (bert): BertForMaskedLM(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=30522, out_features=768, bias=True)\n",
       "  (fc2): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.to(torch.device('cpu'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instanciate our loss function and optimizer. This time though, in order to further combat overfitting we introduce weight decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexf\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optim = AdamW(model2.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the training process.\n",
    "\n",
    "As above we have the same overfitting counter-actions, using the *patience* and *counter* variables in order to keep track of our models performance on the validation subset and stop training when we detect 2 epochs where our model has not shown any improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Batch 1000 / 7226 Training Loss: 0.3072888724477962\n",
      "Batch 2000 / 7226 Training Loss: 0.24175022287806497\n",
      "Batch 3000 / 7226 Training Loss: 0.21568215244814443\n",
      "Batch 4000 / 7226 Training Loss: 0.2007666713037179\n",
      "Batch 5000 / 7226 Training Loss: 0.19166807731366717\n",
      "Batch 6000 / 7226 Training Loss: 0.18500273987813853\n",
      "Batch 7000 / 7226 Training Loss: 0.18002687109737392\n",
      "Batch 1000 / 2008 Validation Loss: 0.14455048449058086\n",
      "Batch 2000 / 2008 Validation Loss: 0.1421097921030596\n",
      "Average Training Loss:  0.179\n",
      "Average Validation Loss: 0.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch:  14%|█▍        | 1/7 [1:56:46<11:40:36, 7006.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "Epoch: 1\n",
      "Batch 1000 / 7226 Training Loss: 0.1470269664605148\n",
      "Batch 2000 / 7226 Training Loss: 0.14454330142971594\n",
      "Batch 3000 / 7226 Training Loss: 0.1439209230328755\n",
      "Batch 4000 / 7226 Training Loss: 0.1431658864080091\n",
      "Batch 5000 / 7226 Training Loss: 0.1418484735670034\n",
      "Batch 6000 / 7226 Training Loss: 0.14669036462534374\n",
      "Batch 7000 / 7226 Training Loss: 0.15180490126264548\n",
      "Batch 1000 / 2008 Validation Loss: 0.18107159739732742\n",
      "Batch 2000 / 2008 Validation Loss: 0.18090481951925905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch:  29%|██▊       | 2/7 [3:52:30<9:40:50, 6970.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss:  0.153\n",
      "Average Validation Loss: 0.181\n",
      "Epoch: 2\n",
      "Batch 1000 / 7226 Training Loss: 0.17730716173909605\n",
      "Batch 2000 / 7226 Training Loss: 0.17897245545592158\n",
      "Batch 3000 / 7226 Training Loss: 0.17807863775640725\n"
     ]
    }
   ],
   "source": [
    "epochs = 7\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "best_loss = 1000000\n",
    "counter = 0\n",
    "patience = 2\n",
    "# Iterate DataLoader\n",
    "for epoch in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "      # Track training loss per epoch\n",
    "      train_loss = 0\n",
    "      # Toggle model on training mode\n",
    "      model2.train()\n",
    "      print(f'Epoch: {epoch}')\n",
    "      for i, (inputs, labels) in enumerate(train_dl):\n",
    "        # Clear optimizer\n",
    "        optim.zero_grad()\n",
    "        # Extract features, attention mask, labels\n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Foward Feed\n",
    "        outputs = model2(input_ids, attention_mask=attention_mask)\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, torch.unsqueeze(labels.float(), 1))\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update Parameters\n",
    "        optim.step()\n",
    "        # Every 1000 batches \n",
    "        train_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "          last_loss = train_loss / (i + 1)\n",
    "          print(f'Batch {i + 1} / {len(train_dl)} Training Loss: {last_loss}')\n",
    "\n",
    "      avg_loss = train_loss / (i + 1)\n",
    "      training_loss.append(avg_loss / (i + 1))\n",
    "      # Track validation loss per epoch\n",
    "      val_loss = 0\n",
    "      # Toggle model on evaluation mode\n",
    "      model2.eval()\n",
    "      # Iterate DataLoader\n",
    "      for i, (inputs, labels) in enumerate(val_dl):\n",
    "          # Extract features, attention mask, labels\n",
    "          input_ids = inputs['input_ids'].to(device)\n",
    "          attention_mask = inputs['attention_mask'].to(device)\n",
    "          labels = labels.to(device)\n",
    "          # Foward Feed\n",
    "          outputs = model2(input_ids, attention_mask=attention_mask)\n",
    "          # Calculate Loss\n",
    "          loss = criterion(outputs, torch.unsqueeze(labels.float(), 1))\n",
    "          val_loss += loss.item()\n",
    "          # Every 1000 batches\n",
    "          if i % 1000 == 999:\n",
    "            last_loss = val_loss / (i + 1)\n",
    "            print(f'Batch {i + 1} / {len(val_dl)} Validation Loss: {last_loss}')\n",
    "      # Track losses for the whole process\n",
    "      avg_val_loss = val_loss / (i + 1)\n",
    "      validation_loss.append(avg_val_loss)\n",
    "      print(f'Average Training Loss: {avg_loss : .3f}')\n",
    "      print(f'Average Validation Loss:{avg_val_loss: .3f}')\n",
    "      # Based on model's improvement, store weights or track overfitting\n",
    "      if avg_val_loss < best_loss:\n",
    "          best_epoch = epoch + 1\n",
    "          best_loss = avg_val_loss\n",
    "          counter = 0\n",
    "          torch.save(model2.state_dict(), f'model_final_{best_epoch}.pt')\n",
    "          print('Model Saved')\n",
    "      else:\n",
    "          counter += 1\n",
    "      # Assess threshold breach\n",
    "      if counter >= patience:\n",
    "          print(f'Early stopping at epoch {epoch + 1} due to overfitting.')\n",
    "          print(f'Best model occured on epoch: {best_epoch}')\n",
    "          break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Since training took place in Google Colab with limited resourses, I only managed to get 3 epochs before getting my runtime shutdown by Google. This plays a significant role to the model's evaluation. In addition to that the best validation loss occured on the first epoch and hence thats the model we are using (meaning its only trained for one epoch)*\n",
    "\n",
    "Time to evaluate our model\n",
    "\n",
    "We convert our data to a list and pass it to the BERT tokenizer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it has been successfully demonstrated that ceramic materials can be joined in the green\\nstate without a second phase by using low pressure injection molded parts. the investigation of the\\njoining interface revealed that a high quality interface can be achieved by carefully adjusting the\\ndifferent manufacturing steps. the use of monomodal particle size distribution in the used powder\\nct3000sg is inferior to a broader particle size distribution obtained by replacing 33% of the finer\\nalumina powder by coarser ct1200sg. in this way the dewaxing process is significantly improved\\nwhen the wall thickness of the part exceeds 3 mm. the investigation of the mechanical properties of\\nthe joined and sintered parts revealed, that the bending strength of the joined specimens achieved\\nabout 80 % of the unjoined, monolithic specimens.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = test_df['abstract'].tolist()\n",
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2009,  2038,  ...,     0,     0,     0],\n",
       "        [  101,  3800,  1999,  ...,     0,     0,     0],\n",
       "        [  101,  2348, 21396,  ...,  2013,  1996,   102],\n",
       "        ...,\n",
       "        [  101,  4372,  5794,  ...,     0,     0,     0],\n",
       "        [  101,  1037,  1012,  ...,     0,     0,     0],\n",
       "        [  101,  2057,  3189,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer1(data_list, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
    "inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the mask array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False,  True, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "mask_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace the True values with the < MASK > token (103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CdindexDataset1(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, Y):\n",
    "        self.encodings = encodings\n",
    "        self.Y = torch.tensor(Y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}, self.Y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instanciate our Dataset and DataLoader objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CdindexDataset1(inputs, test_df['cdindex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_128784\\1932263902.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load saved model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/model_fc3_1.pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\alexf\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    787\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alexf\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alexf\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m             \u001b[0mload_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alexf\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1081\u001b[0m         \u001b[1;31m# stop wrapping with TypedStorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         loaded_storages[key] = torch.storage.TypedStorage(\n\u001b[1;32m-> 1083\u001b[1;33m             \u001b[0mwrap_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m             dtype=dtype)\n\u001b[0;32m   1085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alexf\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mrestore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1055\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1056\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alexf\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alexf\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alexf\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[0;32m    167\u001b[0m                            \u001b[1;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                            \u001b[1;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# Load saved model\n",
    "model2.load_state_dict(torch.load('models/model_fc3_1.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-d3039e29e2d5>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}, self.Y[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss for 1004 samples is 0.14523824602152144\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "test_loss = 0\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i, (inputs, labels) in enumerate(test_dl):\n",
    "  with torch.inference_mode():\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model2(input_ids, attention_mask=attention_mask)\n",
    "    loss = criterion(outputs, torch.unsqueeze(labels.float(), 1))\n",
    "    test_loss += loss.item()\n",
    "    y_true.extend(labels.detach().cpu().numpy())\n",
    "    y_pred.extend(outputs.detach().cpu().numpy())\n",
    "    if i % 999 == 1000:\n",
    "      print(f'Batch {i + 1} Average Test MSE: {test_loss / (i + 1)}')\n",
    "print(f'Average Test Loss for {i + 1} samples is {test_loss / len(test_dl)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.28285327523430587 \n",
      "Mean Squared Error: 0.14519462385321585\n",
      "Root Mean Squared Error: 0.38104412323668746\n",
      "R-squared: 0.1908209530621291\n",
      "Adjusted R-squared: 0.19072013334534144\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_true=y_true, y_pred=y_pred)\n",
    "adjusted_r2 = 1 - (1 - r2) * (len(test_df) - 1) / (len(test_df) - 1 - 1) \n",
    "#adjusted_r2 = 0\n",
    "mse = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)\n",
    "print(f\"Mean Absolute Error: {mae} \\nMean Squared Error: {mse}\\nRoot Mean Squared Error: {rmse}\\nR-squared: {r2}\\nAdjusted R-squared: {adjusted_r2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Since I am working from a laptop without an nvidia gpu, I had to resort to Google Colab in order to access *cuda* gpus. However Colab's resourses are limited and that was a huge burden during this implementation. I believe that with more epochs during training, more layers, incorporation of a tf-idf vectorizer as well as more computational power the model would truly shine.*\n",
    "\n",
    "*Also it would be very beneficial to incorporate the number of citations per paper as a feature for our model, as underlined by the authors. However due to time limitations I was not able to pull it off.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a91554a5e44b4cc609917fc90fb7ad510cda6c3a7bcec5be1f9eaac843308f8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
